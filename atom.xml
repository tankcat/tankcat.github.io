<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Tankcat</title>
  
  <subtitle>I&#39;ll try anything once...</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://tankcat2.com/"/>
  <updated>2017-11-26T10:44:10.061Z</updated>
  <id>http://tankcat2.com/</id>
  
  <author>
    <name>Tankcat</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>十一月的第四周</title>
    <link href="http://tankcat2.com/2017/11/26/diary1126/"/>
    <id>http://tankcat2.com/2017/11/26/diary1126/</id>
    <published>2017-11-26T10:29:45.000Z</published>
    <updated>2017-11-26T10:44:10.061Z</updated>
    
    <content type="html"><![CDATA[<h3 id="工作日的survey"><a href="#工作日的survey" class="headerlink" title="工作日的survey"></a>工作日的survey</h3><p>这个月进行survey的第四周，工作日的五天细读了两篇微软的流处理系统paper，一篇Naiad和一篇Falkirk Wheel；一篇很经典的Dynamo，十年前就发表的这篇今年喜获SIGOPS名人堂奖，重点关注了它的高可用是如何实现的；一篇综述，其中一个作者和Naiad、Falkirk Wheel联系密切，这篇综述关注的点很基础。</p><p>算下来从开始做survey，看过的文章也有二十多篇了，关于容错，心中确实有了一点感觉，但觉得还不够，有的时候回头想想看过的文章，竟然不能一句话讲出它做了什么，看过就忘成了很大的问题。男票告诉我，这是因为我没有理解透彻。所以，现在就有点迷茫，到底什么文章该精读，精读到什么程度是够的，要想真正理解一篇文章的proposal，耗时不短，这当中该怎么做权衡呢？</p><p>还有一点需要反省，就是效率问题，一周只看了四篇文章，很大一部分时间还是被我浪费了，经常看文章看到一半就去找人聊天、逛豆瓣微博，没有完整、高效率的学习时间，这应该也是导致文章理解不透彻的原因之一吧。</p><p>不过，有进步的是，开始定制周计划了，也切实进行了，希望在次基础上提高效率并继续保持。</p><h3 id="周六周日的吃吃玩玩"><a href="#周六周日的吃吃玩玩" class="headerlink" title="周六周日的吃吃玩玩"></a>周六周日的吃吃玩玩</h3><p>周六中午出门，骑单车去武康路的一家星巴克臻选店买工业风的杯子，哪里知道好不容易找到这家店却被告之没有存货，感觉委屈的不行。直接返程肯定是不行的，不然就白出来了，于是就在武昌路和湖南路附近逛逛，后来又去一家网红面店吃了一碗辣肉面。然而，十个网红店九个是垃圾，这家面店很荣幸也是垃圾，38块一碗的面还不如河西食堂3块一碗的阳春面。返程的时候选择步行，正好记一记路线。从武康路-兴国路-华山路-江苏路-愚园路-长宁路-凯旋路-万航渡路-光复西路-枣阳路，短短五公里串联了这么多道路，有些路很小资、适合拍照，有些路就普普通通、大众化。走到长宁路上的兆丰广场，看到有Bose专柜就想顺便试试音质，试玩就心动了，比我的大法轻多了。走之前顺便又去nitori买了一口雪平锅，想着宿舍厨房里有电磁炉，以后可以熬奶茶、煮泡面吃，可是买的时候没看清楚，今天早上发现这锅只能用煤气加热。晚上懒得回实验室了，和男票商量了一下要讨论微信小程序的需求问题，于是又背着包出门，选择在枣阳路的这家星巴克讨论。环境还是不错的，有无线，周六晚上人很少，买了一杯太妃榛果，店员还给了一些蛋糕试吃。讨论完肚子又饿了，就去蔡师傅汤包店点了一碗小馄饨和一块素鸡，美味又划算。最后，回寝室洗漱。哦对了，昨天是老爸生日，舅舅一家去家里，燕子姐姐又给爸爸买了礼物。听老妈说，爸爸这次很感动，不仅燕子姐姐送了礼物，我又送了手机，好像老爸都哭了。</p><p>周日赖了床，早上8点半才醒，准备用雪平锅煮奶茶的时候发现电磁炉不能加热，没办法只能换成电炖锅来做了。牛奶是在盒马鲜生上买的明治鲜奶，加了两包立顿红茶包，这次冰糖又放多了，不过口感还是很醇厚的，虽然比较甜，和外面比起来还是健康很多的。给实验室的小伙伴带了一点，评价都不错。中午去了实验室，忙着把Hexo个人博客需要的环境在新笔记本上重新搭建了一下，遇到了不少问题，但是都解决了。搞完已经三点了，在大众点评上选择了一家中江路那边的日料店，骑了单车过去，由于不是饭点，店里除了我没其他顾客，点了三文鱼刺身、炸土豆饼、煎饺和炸鸡肉串，很快就消灭了~</p><h3 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h3><p>这一周过得还是挺充实了，周一早上体重还下百了，激动得我发了一条朋友圈。可是下百就一天，接着几天就无所顾忌地吃，周一把剩余的牛油果继续做了奶昔喝，周二吃了冒菜，周三又跑去吃了煲宫，周五还吃了麻辣香锅和芝麻糊小圆子，周六周日前面已经说了。减肥我还是会继续的，只是不会再像一开始那么严格了，该吃吃还是要吃，该锻炼也还是会锻炼，健康的前提下保持身材。技能上，</p><p>就这样吧，明天又是新的一周，下周五轮到我讲survey，还有四天半的时间好好准备，加油吧二筒子~</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      一周的流水线，只是记录，文笔很差。
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="周记" scheme="http://tankcat2.com/tags/%E5%91%A8%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Martiderm安瓶使用感</title>
    <link href="http://tankcat2.com/2017/11/24/Martiderm/"/>
    <id>http://tankcat2.com/2017/11/24/Martiderm/</id>
    <published>2017-11-24T01:28:31.000Z</published>
    <updated>2017-11-26T06:16:30.824Z</updated>
    
    <content type="html"><![CDATA[<p>这又是一记安利~</p><p>先交代一下本人的肤质吧：</p><ol><li>初中开始长青春痘</li><li>高中不懂事，乱扣红肿痘痘，导致右脸比较深的痘印</li><li>前两年断断续续吃过维安脂和泰尔斯，现在出油不严重，冬天甚至会有点干</li><li>目前下巴仍然会长痘痘，以红肿为主，闭口很少；下巴以上部位不怎么长</li></ol><p>总结一句话，就是<strong>混油痘肌</strong>。</p><p>半个月前左右我抱着尝试的心理买了Martiderm家的安瓶，<strong>臻活</strong>和<strong>平衡</strong>系列各五只，我的目的很明确，祛痘印+提亮肤色。</p><p>臻活系列貌似是价格最高的，浓度和粘稠度也是，这个我是睡前用；平衡系列是早上用，没有臻活那么黏。这两个我都是两天之内用完一瓶，一开始我是先用<strong>伊索的绿茶水和无油保湿精华</strong>打个底，后来嫌麻烦，就直接把安瓶和无油保湿精华混在一起抹了，吸收挺快的。</p><p>可能是刚开始用的时候不耐受，加上我没控制好量，涂的有点多，导致不论是睡醒还是白天一天下来，都觉得自己脸色暗沉，毛孔更大….但是！从前天早上开始，我发现脸上干净了好多，下巴上的痘痘痘印(除红肿外)淡了不少，关键是毛孔小了！看来这个安瓶在微博上风很大是有道理的！现在快用完了，打算入手一个全套装~价格好像更划算~</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这又是一记安利~&lt;/p&gt;
&lt;p&gt;先交代一下本人的肤质吧：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;初中开始长青春痘&lt;/li&gt;
&lt;li&gt;高中不懂事，乱扣红肿痘痘，导致右脸比较深的痘印&lt;/li&gt;
&lt;li&gt;前两年断断续续吃过维安脂和泰尔斯，现在出油不严重，冬天甚至会有点干&lt;/li&gt;
&lt;li&gt;目前下巴仍然会长痘痘，以红肿为主，闭口很少；下巴以上部位不怎么长&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总结一句话，就是&lt;strong&gt;混油痘肌&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;半个月前左右我抱着尝试的心理买了Martiderm家的安瓶，&lt;strong&gt;臻活&lt;/strong&gt;和&lt;strong&gt;平衡&lt;/strong&gt;系列各五只，我的目的很明确，祛痘印+提亮肤色。&lt;/p&gt;
&lt;p&gt;臻活系列貌似是价格最高的，浓度和粘稠度也是，这个我是睡前用；平衡系列是早上用，没有臻活那么黏。这两个我都是两天之内用完一瓶，一开始我是先用&lt;strong&gt;伊索的绿茶水和无油保湿精华&lt;/strong&gt;打个底，后来嫌麻烦，就直接把安瓶和无油保湿精华混在一起抹了，吸收挺快的。&lt;/p&gt;
&lt;p&gt;可能是刚开始用的时候不耐受，加上我没控制好量，涂的有点多，导致不论是睡醒还是白天一天下来，都觉得自己脸色暗沉，毛孔更大….但是！从前天早上开始，我发现脸上干净了好多，下巴上的痘痘痘印(除红肿外)淡了不少，关键是毛孔小了！看来这个安瓶在微博上风很大是有道理的！现在快用完了，打算入手一个全套装~价格好像更划算~&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="护肤" scheme="http://tankcat2.com/tags/%E6%8A%A4%E8%82%A4/"/>
    
      <category term="安瓶" scheme="http://tankcat2.com/tags/%E5%AE%89%E7%93%B6/"/>
    
      <category term="Martiderm" scheme="http://tankcat2.com/tags/Martiderm/"/>
    
  </entry>
  
  <entry>
    <title>视频导出音频小技能</title>
    <link href="http://tankcat2.com/2017/11/22/ffmped/"/>
    <id>http://tankcat2.com/2017/11/22/ffmped/</id>
    <published>2017-11-22T02:44:51.000Z</published>
    <updated>2017-11-26T06:17:18.404Z</updated>
    
    <content type="html"><![CDATA[<p>早上看到青峰发的新作品小视频，就想把它down下来，于是找到了一个很实用的chrome插件——video download helper。</p><p>视频下载下来了，又想提取音频，这样上传到我的网易云网盘就能随时听啦。一开始不太想装国产的转换软件，发现了一个在线的转换平台——<a href="http://audio-extractor.net/cn/" target="_blank" rel="noopener">http://audio-extractor.net/cn/</a>，需要先上传视频，再点击转换，最后再下载音频。</p><p>视频上传实在是太慢了！于是乎我又去知乎上搜搜看有没有大神提供一些轻量级的软件~果不其然，让我发现了FFmpeg的存在！<a href="http://ffmpeg.org/" target="_blank" rel="noopener">http://ffmpeg.org/ </a>这个是homepage，支持Linux/Windows/OS X。下载好压缩包后解压，然后把bin目录添加到环境变量中去就能愉快地使用啦~</p><p>我是把MP4转换成MP3，在别人的博客里找到了下面的命令：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ffmpeg -i video.mp4 -vn-acodec libmp3lame -ac 2 -qscale:a 4 -ar 48000audio.mp3</span><br></pre></td></tr></table></figure><p>以上，谢谢阅读。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;早上看到青峰发的新作品小视频，就想把它down下来，于是找到了一个很实用的chrome插件——video download helper。&lt;/p&gt;
&lt;p&gt;视频下载下来了，又想提取音频，这样上传到我的网易云网盘就能随时听啦。一开始不太想装国产的转换软件，发现了一个在线的转换平台——&lt;a href=&quot;http://audio-extractor.net/cn/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://audio-extractor.net/cn/&lt;/a&gt;，需要先上传视频，再点击转换，最后再下载音频。&lt;/p&gt;
&lt;p&gt;视频上传实在是太慢了！于是乎我又去知乎上搜搜看有没有大神提供一些轻量级的软件~果不其然，让我发现了FFmpeg的存在！&lt;a href=&quot;http://ffmpeg.org/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://ffmpeg.org/ &lt;/a&gt;这个是homepage，支持Linux/Windows/OS X。下载好压缩包后解压，然后把bin目录添加到环境变量中去就能愉快地使用啦~&lt;/p&gt;
&lt;p&gt;我是把MP4转换成MP3，在别人的博客里找到了下面的命令：&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;ffmpeg -i video.mp4 -vn-acodec libmp3lame -ac 2 -qscale:a 4 -ar 48000audio.mp3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;以上，谢谢阅读。&lt;/p&gt;
    
    </summary>
    
      <category term="技能树" scheme="http://tankcat2.com/categories/%E6%8A%80%E8%83%BD%E6%A0%91/"/>
    
    
      <category term="ffmpeg" scheme="http://tankcat2.com/tags/ffmpeg/"/>
    
      <category term="音频" scheme="http://tankcat2.com/tags/%E9%9F%B3%E9%A2%91/"/>
    
      <category term="视频" scheme="http://tankcat2.com/tags/%E8%A7%86%E9%A2%91/"/>
    
  </entry>
  
  <entry>
    <title>鼓楼半日记</title>
    <link href="http://tankcat2.com/2017/08/15/gulou/"/>
    <id>http://tankcat2.com/2017/08/15/gulou/</id>
    <published>2017-08-15T12:11:31.000Z</published>
    <updated>2017-08-21T14:25:40.000Z</updated>
    
    <content type="html"><![CDATA[<p>今天跟着zf去鼓楼的办公室，发现大门口右手边就是云南路地铁站口，右拐过去就是上海路。想到小厨娘就在附近，决定扔下zf一个人去买蛋糕。不知道怎么想的，可能天不热，没骑车步行过去的。以前步行只知道跟着导航急匆匆地赶到目的地，不在意沿途的风景。今天边走变看，走着走着就看到了最喜欢吃的朱师傅梅花糕。以前领过很多人来吃，都是跟着导航走，今天无意间走到，感觉很奇妙。上海路起起伏伏，回来骑车的时候感觉更明显。从上海路拐进广州路，人越来越多，后来发现是到了儿童医院。最后终于找到小厨娘，被告知想吃的抹茶盒子下午两点才有，说好的要芒果班戟，回来一吃发现拿的是榴莲。</p><p>快到办公室的时候开始下雷阵雨，快去跑回去，没过一会儿雨就停了。两个人中午商量着吃什么，其实这个商圈好吃的很多，韩料啦，串串啦，西餐啦，大众点评上好多评分高的店铺。但是雨停了之后太阳出来了，有点热，两个人都不太想吃辣的，于是就索性吃了鸡鸣汤包。上次去还是清明节。去的路上无意间看到一家小咖啡店，发现店家品味跟我一样哈，竟然想起来用伊索的瓶子插花。<br><a id="more"></a><br><img src="http://7xwggp.com1.z0.glb.clouddn.com/yisuo.jpg" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;今天跟着zf去鼓楼的办公室，发现大门口右手边就是云南路地铁站口，右拐过去就是上海路。想到小厨娘就在附近，决定扔下zf一个人去买蛋糕。不知道怎么想的，可能天不热，没骑车步行过去的。以前步行只知道跟着导航急匆匆地赶到目的地，不在意沿途的风景。今天边走变看，走着走着就看到了最喜欢吃的朱师傅梅花糕。以前领过很多人来吃，都是跟着导航走，今天无意间走到，感觉很奇妙。上海路起起伏伏，回来骑车的时候感觉更明显。从上海路拐进广州路，人越来越多，后来发现是到了儿童医院。最后终于找到小厨娘，被告知想吃的抹茶盒子下午两点才有，说好的要芒果班戟，回来一吃发现拿的是榴莲。&lt;/p&gt;
&lt;p&gt;快到办公室的时候开始下雷阵雨，快去跑回去，没过一会儿雨就停了。两个人中午商量着吃什么，其实这个商圈好吃的很多，韩料啦，串串啦，西餐啦，大众点评上好多评分高的店铺。但是雨停了之后太阳出来了，有点热，两个人都不太想吃辣的，于是就索性吃了鸡鸣汤包。上次去还是清明节。去的路上无意间看到一家小咖啡店，发现店家品味跟我一样哈，竟然想起来用伊索的瓶子插花。&lt;br&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
  </entry>
  
  <entry>
    <title>Tragic Ending or Peace Ending ?</title>
    <link href="http://tankcat2.com/2017/07/21/my%20chester/"/>
    <id>http://tankcat2.com/2017/07/21/my chester/</id>
    <published>2017-07-20T16:00:00.000Z</published>
    <updated>2017-07-21T01:44:52.000Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>那个一直嘶吼的他走了，在很多人的青春中躁动的声音消失了，这个世界总是留不住想要留住的人….</p></blockquote><p>收拾好准备出宿舍门的时候，打开朋友圈，看到有好友转发西菇自杀了，晴天霹雳。</p><p>各大媒体、社交平台都开始报道这个消息，朋友圈也开始各种转发，大家明明都还沉浸在新收到的新单mv的推送中，可他就这么离开了。</p><p>有的人可能只知道lol登陆界面上的numb，有的人可能是变形金刚的bgm what i’ve done，new divide和iridescent而知道linkin park，有的人可能是因为今天的朋友圈被告知有个乐队的主场自杀了。高三一次月考作文我就以西菇为题材，写了他从悲惨的童年到获得如今的成就，写了他的纹身，他的耳洞，他的嗓音转变，他的专辑，他的这条路到底是有多心酸、坚强与挣扎。他的作品获得了无数粉丝的喜爱，无疑他的作品来源于悲惨的童年经历，但这段经历如今又带走了他的生命，这些因果到底是矛盾的。</p><p>西菇的自杀让我想到台湾女作家林奕含，一样是童年被x侵，一样是在作品中透露出自己的无奈和无助，他们感受到的痛苦是真真切切的。可能在挣扎中想要积极向上，也确实创造了许多作品激励并拯救了许多同样饱受苦痛折磨的人，但喧嚣与欢乐始终都是别人的，音乐只是病痛的舒缓剂，不是所有的经历都能云淡风轻地过去，有些事每每回想，总是锥心地痛一次。时间不是万能的，抑郁的人自杀也不是矫情。</p><p>他的死对至亲和粉丝来说无疑是悲惨的结局，但他的前半生可能一直在寻找somewhere i belong，而今日凌晨，他找到了。</p><p>I wanna let go of the pain I’ve felt so long…</p><p>somewhere i belong…</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;那个一直嘶吼的他走了，在很多人的青春中躁动的声音消失了，这个世界总是留不住想要留住的人….&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;收拾好准备出宿舍门的时候，打开朋友圈，看到有好友转发西菇自杀了，晴天霹雳。&lt;/p&gt;
&lt;p&gt;各大媒体、社交平台都开始报道这个消息，朋友圈也开始各种转发，大家明明都还沉浸在新收到的新单mv的推送中，可他就这么离开了。&lt;/p&gt;
&lt;p&gt;有的人可能只知道lol登陆界面上的numb，有的人可能是变形金刚的bgm what i’ve done，new divide和iridescent而知道linkin park，有的人可能是因为今天的朋友圈被告知有个乐队的主场自杀了。高三一次月考作文我就以西菇为题材，写了他从悲惨的童年到获得如今的成就，写了他的纹身，他的耳洞，他的嗓音转变，他的专辑，他的这条路到底是有多心酸、坚强与挣扎。他的作品获得了无数粉丝的喜爱，无疑他的作品来源于悲惨的童年经历，但这段经历如今又带走了他的生命，这些因果到底是矛盾的。&lt;/p&gt;
&lt;p&gt;西菇的自杀让我想到台湾女作家林奕含，一样是童年被x侵，一样是在作品中透露出自己的无奈和无助，他们感受到的痛苦是真真切切的。可能在挣扎中想要积极向上，也确实创造了许多作品激励并拯救了许多同样饱受苦痛折磨的人，但喧嚣与欢乐始终都是别人的，音乐只是病痛的舒缓剂，不是所有的经历都能云淡风轻地过去，有些事每每回想，总是锥心地痛一次。时间不是万能的，抑郁的人自杀也不是矫情。&lt;/p&gt;
&lt;p&gt;他的死对至亲和粉丝来说无疑是悲惨的结局，但他的前半生可能一直在寻找somewhere i belong，而今日凌晨，他找到了。&lt;/p&gt;
&lt;p&gt;I wanna let go of the pain I’ve felt so long…&lt;/p&gt;
&lt;p&gt;somewhere i belong…&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="Linkin Park" scheme="http://tankcat2.com/tags/Linkin-Park/"/>
    
      <category term="Chester Bennington" scheme="http://tankcat2.com/tags/Chester-Bennington/"/>
    
  </entry>
  
  <entry>
    <title>Storm UI详解</title>
    <link href="http://tankcat2.com/2017/05/22/storm_ui/"/>
    <id>http://tankcat2.com/2017/05/22/storm_ui/</id>
    <published>2017-05-22T08:32:31.000Z</published>
    <updated>2017-07-20T00:45:32.000Z</updated>
    
    <content type="html"><![CDATA[<p><img src="http://7xwggp.com1.z0.glb.clouddn.com/storm_ui_config_summary.png" alt=""></p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;img src=&quot;http://7xwggp.com1.z0.glb.clouddn.com/storm_ui_config_summary.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Storm学习之路" scheme="http://tankcat2.com/categories/Storm%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/"/>
    
    
      <category term="storm" scheme="http://tankcat2.com/tags/storm/"/>
    
      <category term="storm ui" scheme="http://tankcat2.com/tags/storm-ui/"/>
    
  </entry>
  
  <entry>
    <title>Storm Kafka之KafkaSpout</title>
    <link href="http://tankcat2.com/2017/05/18/KafkaSpout/"/>
    <id>http://tankcat2.com/2017/05/18/KafkaSpout/</id>
    <published>2017-05-18T12:11:31.000Z</published>
    <updated>2017-07-20T00:46:14.000Z</updated>
    
    <content type="html"><![CDATA[<p><code>storm-kafka-XXX.jar</code>提供了核心Storm与Trident的组件Spout的代码实现，用于消费Kafka中存储的数据(0.8.x之后的版本)。本文只介绍核心Storm的KafkaSpout。</p><p>对于核心Storm与Trident两个版本的Spout实现，提供了<code>BrokerHost</code>接口，跟踪Kafka broker host$\rightarrow$partition的映射，并提供<code>KafkaConfig</code>接口来控制Kafka相关的参数。下面就这以上两点进行讲解。</p><h3 id="BrokerHost"><a href="#BrokerHost" class="headerlink" title="BrokerHost"></a>BrokerHost</h3><p>为了对Kafka spout进行初始化，我们需要创建一个<code>BrokerHost</code>的实例，Storm共提供了两种实现方式：</p><ol><li><p>ZkHosts。ZkHosts使用Zookeeper的实体对象，可动态地追踪Kafka broker$\rightarrow$partition之间的映射，通过调用下面两种函数创建ZkHosts:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ZkHosts</span><span class="params">(String brokerZkStr,String brokerZkPath)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ZkHosts</span><span class="params">(String brokerZkStr)</span></span></span><br></pre></td></tr></table></figure><p>其中，<code>brokerZkStr</code>是<code>ip:host</code>(主机:端口)，<code>brokerZkPath</code>是存放所有topic和partition信息的根目录，默认值为<code>\broker</code>。默认地，Zookepper每60秒刷新一次broker$\rightarrow$partition，通过<code>host:refreshFreqSecs</code>可以改变这个时间。</p></li></ol><a id="more"></a><ol><li><p>StaticHosts。这是另一个选择，不过broker$\rightarrow$partition之间的映射关系是静态的，创建这个类的实例之前，需要首选创建<code>GlobalPartitionInformation</code>类的实例，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Broker brokerForPartition0 = <span class="keyword">new</span> Broker(<span class="string">"localhost"</span>);<span class="comment">//localhost:9092,端口号默认为9092</span></span><br><span class="line">Broker brokerForPartition1 = <span class="keyword">new</span> Broker(<span class="string">"localhost"</span>,<span class="number">9092</span>);<span class="comment">//localhost:9092,显示地指定端口号</span></span><br><span class="line">Broker brokerForPartition2 = <span class="keyword">new</span> Broker(<span class="string">"localhost:9092"</span>);</span><br><span class="line">GlobalPartitionInformation partitionInfo = <span class="keyword">new</span> GlobalPartitionInformation();</span><br><span class="line">partitionInfo.addPartition(<span class="number">0</span>, brokerFroPartition0);<span class="comment">// partition0 到 brokerForPartition0的映射</span></span><br><span class="line">partitionInfo.addPartition(<span class="number">1</span>, brokerFroPartition1);</span><br><span class="line">partitionInfo.addPartition(<span class="number">2</span>, brokerFroPartition2);</span><br><span class="line">StaticHosts hosts = <span class="keyword">new</span> StaticHosts(partitionInfo);</span><br></pre></td></tr></table></figure></li></ol><h3 id="KafkaConfig"><a href="#KafkaConfig" class="headerlink" title="KafkaConfig"></a>KafkaConfig</h3><p>创建KafkaSpout需要的另一个参数是<code>KafaConfig</code>，通过调用以下两个函数进行对象创建：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">KafkaConfig</span><span class="params">(BrokerHosts host,String topic)</span></span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">KafkaConfig</span><span class="params">(BrokerHosts host,String topic,String clientId)</span></span></span><br></pre></td></tr></table></figure><p>其中，<code>host</code>可以为BrokerHost的任何一种实现，<code>topic</code>是一个topic的名称，<code>clientId</code>是一个可选择的参数，作为Zookeeper路径的一部分，存储spout当前数据读取的offset。</p><p>目前，KafkaConfig有两种扩展形式，<code>SpoutcConfig</code>提供额外的Zookeeper连接的字段信息，用于控制KafkaSpout特定的行为。<code>zkRoot</code>用于存储consumer的offset，<code>id</code>用于唯一标识当前的spout。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">SpoutConfig</span><span class="params">(BrokerHosts hosts,String topic,String zkRoot,String id)</span></span></span><br></pre></td></tr></table></figure><p>除了以上参数，SpoutConfig包括如下的字段值，用来控制KafkaSpout：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//将当前的offset保存到Zookeeper的频率</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">long</span> stateUpdateIntervals = <span class="number">2000</span>;</span><br><span class="line"><span class="comment">//用于失效消息的重试策略</span></span><br><span class="line"><span class="keyword">public</span> String failedMsgRetryManagerClass = ExponentialBackofMsgRetryManager.class.getName();</span><br><span class="line"><span class="comment">//指数级别的back-off重试设置。在一个bolt调用OutputCollector.fail()后，用于重新设置的ExponentialBackoffMsgRetryManager。只有在ExponentialBackoffMsgRetryManager被使用时，才有效果。</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">long</span> retryInitialDetails = <span class="number">0</span>;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">double</span> retryDelayMultiplier = <span class="number">1.0</span>;</span><br><span class="line"><span class="comment">//连续重试之间的最大延时</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">long</span> retryDelayMaxMs = <span class="number">60</span> * <span class="number">1000</span>;</span><br><span class="line"><span class="comment">//当retryLimit低于0时，不停地重新发送失效的消息</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> retryLimit = -<span class="number">1</span>;</span><br></pre></td></tr></table></figure><p>KafkaSpout只接收一个SpoutConfig的实例作为参数。</p><p>下面给出一个实例：</p><ol><li><p>首先创建一个名为<code>couple</code>的topic，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:3030 --partitions 4 --replication-factor 1 --topic couple</span><br></pre></td></tr></table></figure></li><li><p>写一个简单的Producer，将文件<code>string_data.txt</code>的记录发送到<code>couple</code>中，如下：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">kafkaFileProducer</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String topic_name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String file_name;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> KafkaProducer&lt;String,String&gt; producer;</span><br><span class="line">    <span class="keyword">private</span> Boolean isAsync;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">kafkaFileProducer</span><span class="params">(String topic_name,String file_name,Boolean isAsync)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.file_name=file_name;</span><br><span class="line">        <span class="keyword">this</span>.topic_name=topic_name;</span><br><span class="line">        Properties properties=<span class="keyword">new</span> Properties();</span><br><span class="line">        properties.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">        properties.put(<span class="string">"client.id"</span>,<span class="string">"CoupleProducer"</span>);</span><br><span class="line">        properties.put(<span class="string">"key.serializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        properties.put(<span class="string">"value.serializer"</span>,<span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        producer=<span class="keyword">new</span> KafkaProducer&lt;String, String&gt;(properties);</span><br><span class="line">        <span class="keyword">this</span>.isAsync=isAsync;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessage</span><span class="params">(String key,String value)</span></span>&#123;</span><br><span class="line">        <span class="keyword">long</span> start_time=System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">if</span>(isAsync)&#123;</span><br><span class="line">            producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(topic_name,key),<span class="keyword">new</span> CoupleCallBack(start_time,key,value));</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                producer.send(<span class="keyword">new</span> ProducerRecord&lt;String, String&gt;(topic_name,key,value)).get();</span><br><span class="line">                System.out.println(<span class="string">"Sent message : ( "</span>+key+<span class="string">" , "</span>+value+<span class="string">" )"</span>);</span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (ExecutionException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        String file_name=<span class="string">"DataSource/Data/string_data.txt"</span>;</span><br><span class="line">        String topic_name=<span class="string">"couple"</span>;</span><br><span class="line">        kafkaFileProducer producer=<span class="keyword">new</span> kafkaFileProducer(topic_name,file_name,<span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">int</span> lineCount=<span class="number">0</span>;</span><br><span class="line">        FileInputStream fis=<span class="keyword">null</span>;</span><br><span class="line">        BufferedReader br=<span class="keyword">null</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            fis=<span class="keyword">new</span> FileInputStream(file_name);</span><br><span class="line">            br=<span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(fis));</span><br><span class="line">            String line=<span class="keyword">null</span>;</span><br><span class="line">            <span class="keyword">while</span>((line=br.readLine())!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                lineCount++;</span><br><span class="line">                producer.sendMessage(lineCount+<span class="string">""</span>,line);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (FileNotFoundException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="class"><span class="keyword">class</span> <span class="title">CoupleCallBack</span> <span class="keyword">implements</span> <span class="title">Callback</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">long</span> start_time;</span><br><span class="line">        <span class="keyword">private</span> String key;</span><br><span class="line">        <span class="keyword">private</span> String message;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">CoupleCallBack</span><span class="params">(<span class="keyword">long</span> start_time, String key, String message)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.start_time = start_time;</span><br><span class="line">            <span class="keyword">this</span>.key = key;</span><br><span class="line">            <span class="keyword">this</span>.message = message;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">/*</span></span><br><span class="line"><span class="comment">            A callback method</span></span><br><span class="line"><span class="comment">            The user can implement to provide asynchronous handling of request completion.</span></span><br><span class="line"><span class="comment">            The method will be called when the record sent to the server has been acknowledged.</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onCompletion</span><span class="params">(RecordMetadata recordMetadata, Exception e)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">long</span> elapsed_time=System.currentTimeMillis()-start_time;</span><br><span class="line">            <span class="keyword">if</span>(recordMetadata!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                System.out.println(<span class="string">"Message( "</span>+key+<span class="string">" , "</span>+ message+<span class="string">" ) sent to partition("</span>+recordMetadata.partition()+<span class="string">" ) , offset("</span> +recordMetadata.offset()+<span class="string">" ) in "</span>+elapsed_time+<span class="string">" ms"</span>);</span><br><span class="line">            &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>编写一个简单的Storm Topology，利用KafkaSpout读取couple中的数据(一条条的句子)，并分割成一个个的单词，统计单词个数，如下：</p><ul><li><p>SplitSentenceBolt</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitSentenceBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector basicOutputCollector)</span> </span>&#123;</span><br><span class="line">        String sentence=tuple.getStringByField(<span class="string">"msg"</span>);</span><br><span class="line">        System.out.println(tuple.getSourceTask()+<span class="string">":"</span>+sentence);</span><br><span class="line">        String[] words=sentence.split(<span class="string">" "</span>);</span><br><span class="line">        <span class="keyword">for</span>(String word:words)&#123;</span><br><span class="line">            basicOutputCollector.emit(<span class="keyword">new</span> Values(word));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>WordCountBolt</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,Long&gt; counts=<span class="keyword">null</span>;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">prepare</span><span class="params">(Map conf,TopologyContext context)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.counts=<span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line">        <span class="keyword">super</span>.prepare(conf,context);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector basicOutputCollector)</span> </span>&#123;</span><br><span class="line">        String word=tuple.getStringByField(<span class="string">"word"</span>);</span><br><span class="line">        Long count=<span class="keyword">this</span>.counts.get(word);</span><br><span class="line">        <span class="keyword">if</span>(count==<span class="keyword">null</span>)</span><br><span class="line">            count=<span class="number">0L</span>;</span><br><span class="line">        count++;</span><br><span class="line">        <span class="keyword">this</span>.counts.put(word,count);</span><br><span class="line">        basicOutputCollector.emit(<span class="keyword">new</span> Values(word,count));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"word"</span>,<span class="string">"count"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>ReportBolt</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReportBolt</span> <span class="keyword">extends</span> <span class="title">BaseBasicBolt</span></span>&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">execute</span><span class="params">(Tuple tuple, BasicOutputCollector basicOutputCollector)</span> </span>&#123;</span><br><span class="line">        String word=tuple.getStringByField(<span class="string">"word"</span>);</span><br><span class="line">        Long count=tuple.getLongByField(<span class="string">"count"</span>);</span><br><span class="line">        String reportMsg=<span class="string">"&#123; word : "</span>+word+<span class="string">" , count : "</span>+count+<span class="string">" &#125;"</span>;</span><br><span class="line">        basicOutputCollector.emit(<span class="keyword">new</span> Values(reportMsg));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">declareOutputFields</span><span class="params">(OutputFieldsDeclarer outputFieldsDeclarer)</span> </span>&#123;</span><br><span class="line">        outputFieldsDeclarer.declare(<span class="keyword">new</span> Fields(<span class="string">"message"</span>));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>KafkaWordCountTopology</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountKafkaTopology</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String KAFKA_SPOUT_ID=<span class="string">"kafka-spout"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String SPLIT_BOLT_ID=<span class="string">"split-bolt"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String WORD_COUNT_BOLT_ID=<span class="string">"word-count-bolt"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String REPORT_BOLT_ID=<span class="string">"report-bolt"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String CONSUME_TOPIC=<span class="string">"couple"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PRODUCT_TOPIC=<span class="string">"test"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ZK_ROOT=<span class="string">"/couple"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String ZK_ID=<span class="string">"wordcount"</span>;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String TOPOLOGY_NAME=<span class="string">"word-count-topology"</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span></span>&#123;</span><br><span class="line">        BrokerHosts brokerHosts=<span class="keyword">new</span> ZkHosts(<span class="string">"192.168.1.118:3030"</span>);</span><br><span class="line">        SpoutConfig spoutConfig=<span class="keyword">new</span> SpoutConfig(brokerHosts,CONSUME_TOPIC,ZK_ROOT,ZK_ID);</span><br><span class="line"></span><br><span class="line">        spoutConfig.scheme = <span class="keyword">new</span> SchemeAsMultiScheme(<span class="keyword">new</span> MessageScheme());</span><br><span class="line"></span><br><span class="line">        TopologyBuilder builder=<span class="keyword">new</span> TopologyBuilder();</span><br><span class="line">        builder.setSpout(KAFKA_SPOUT_ID,<span class="keyword">new</span> KafkaSpout(spoutConfig),<span class="number">3</span>);<span class="comment">//需要注意的是，spout的并行度不能超过topic的partition个数！</span></span><br><span class="line">        builder.setBolt(SPLIT_BOLT_ID,<span class="keyword">new</span> SplitSentenceBolt(),<span class="number">1</span>).shuffleGrouping(KAFKA_SPOUT_ID);</span><br><span class="line">        builder.setBolt(WORD_COUNT_BOLT_ID,<span class="keyword">new</span> WordCountBolt()).fieldsGrouping(SPLIT_BOLT_ID,<span class="keyword">new</span> Fields(<span class="string">"word"</span>));</span><br><span class="line">        builder.setBolt(REPORT_BOLT_ID,<span class="keyword">new</span> ReportBolt()).shuffleGrouping(WORD_COUNT_BOLT_ID);</span><br><span class="line">        <span class="comment">//builder.setBolt(KAFKA_BOLT_ID,new KafkaBolt&lt;String,Long&gt;()).shuffleGrouping(REPORT_BOLT_ID);</span></span><br><span class="line"></span><br><span class="line">        Config config=<span class="keyword">new</span> Config();</span><br><span class="line">        Map&lt;String,String&gt; map=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        <span class="comment">//map.put("metadata.broker.list", "localhost:9092");</span></span><br><span class="line">        map.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"localhost:9092"</span>);</span><br><span class="line">    map.put(<span class="string">"serializer.class"</span>,<span class="string">"kafka.serializer.StringEncoder"</span>);</span><br><span class="line">        config.put(<span class="string">"kafka.broker.properties"</span>,map);</span><br><span class="line">        config.setNumWorkers(<span class="number">3</span>);</span><br><span class="line">      </span><br><span class="line">        LocalCluster cluster=<span class="keyword">new</span> LocalCluster();</span><br><span class="line"> cluster.submitTopology(TOPOLOGY_NAME,config,builder.createTopology());</span><br><span class="line">        Utils.sleep(<span class="number">10000</span>);</span><br><span class="line">        cluster.killTopology(TOPOLOGY_NAME);</span><br><span class="line">        cluster.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>​</p></li></ul></li></ol>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;code&gt;storm-kafka-XXX.jar&lt;/code&gt;提供了核心Storm与Trident的组件Spout的代码实现，用于消费Kafka中存储的数据(0.8.x之后的版本)。本文只介绍核心Storm的KafkaSpout。&lt;/p&gt;
&lt;p&gt;对于核心Storm与Trident两个版本的Spout实现，提供了&lt;code&gt;BrokerHost&lt;/code&gt;接口，跟踪Kafka broker host$\rightarrow$partition的映射，并提供&lt;code&gt;KafkaConfig&lt;/code&gt;接口来控制Kafka相关的参数。下面就这以上两点进行讲解。&lt;/p&gt;
&lt;h3 id=&quot;BrokerHost&quot;&gt;&lt;a href=&quot;#BrokerHost&quot; class=&quot;headerlink&quot; title=&quot;BrokerHost&quot;&gt;&lt;/a&gt;BrokerHost&lt;/h3&gt;&lt;p&gt;为了对Kafka spout进行初始化，我们需要创建一个&lt;code&gt;BrokerHost&lt;/code&gt;的实例，Storm共提供了两种实现方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;ZkHosts。ZkHosts使用Zookeeper的实体对象，可动态地追踪Kafka broker$\rightarrow$partition之间的映射，通过调用下面两种函数创建ZkHosts:&lt;/p&gt;
&lt;figure class=&quot;highlight java&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ZkHosts&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String brokerZkStr,String brokerZkPath)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;ZkHosts&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(String brokerZkStr)&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;其中，&lt;code&gt;brokerZkStr&lt;/code&gt;是&lt;code&gt;ip:host&lt;/code&gt;(主机:端口)，&lt;code&gt;brokerZkPath&lt;/code&gt;是存放所有topic和partition信息的根目录，默认值为&lt;code&gt;\broker&lt;/code&gt;。默认地，Zookepper每60秒刷新一次broker$\rightarrow$partition，通过&lt;code&gt;host:refreshFreqSecs&lt;/code&gt;可以改变这个时间。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Storm学习之路" scheme="http://tankcat2.com/categories/Storm%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/"/>
    
    
      <category term="kafka" scheme="http://tankcat2.com/tags/kafka/"/>
    
      <category term="storm" scheme="http://tankcat2.com/tags/storm/"/>
    
  </entry>
  
  <entry>
    <title>列存储中常见压缩技术</title>
    <link href="http://tankcat2.com/2017/05/11/compression/"/>
    <id>http://tankcat2.com/2017/05/11/compression/</id>
    <published>2017-05-11T05:40:00.000Z</published>
    <updated>2017-07-20T00:46:44.000Z</updated>
    
    <content type="html"><![CDATA[<p>在列数据库中，实用面向列的压缩算法进行数据压缩，并且在处理数据时保持压缩的形式，即不通过解压来处理数据，很大程度上提升了查询性能.凭直觉就能知道，以列为存储形式的数据比以行为存储形式的数据更容易压缩.当处理的数据信息熵较低，即数据的局部性较高，那么压缩算法的性能越好.举个列子来说吧，现在有一张顾客表，包含了[姓名，电话，邮箱，传真]等属性.列存储使得所有的姓名存储在一起，所有的电话号码存储在一起.有一点可以确定的是，电话号码各自之间是要比周围其他属性的数值来得更加相似的.</p><p><strong>压缩的优势具体是什么呢？</strong>总结起来呢有两点：</p><ol><li>减少I/O操作次数.如果数据被压缩了，那么其实一次I/O读取(磁盘到内存/CPU)实际对应的源数据是远远超过不使用压缩技术的读取.</li><li>提高查询性能.如果查询执行器可以直接在压缩后的数据上进行操作，在进行具体的操作时不需要进行解压，而这个操作一般开销较大.</li></ol><p>列存储的压缩技术一般有消零和空格符算法(Null Supression)、Lerrpel-Ziv算法、词典编码算法(Dictionary Encoding)、行程编码算法(Run-length Encoding)、位向量算法(Bit-Vector Encoding)，其中较为常见的是后三种，接下来也重点介绍这三种.</p><a id="more"></a><h3 id="行程编码-Run-length-Encoding"><a href="#行程编码-Run-length-Encoding" class="headerlink" title="行程编码 Run-length Encoding"></a>行程编码 Run-length Encoding</h3><p>行程编码的核心思想是将有序列中的相同元素转化成一个三元组&lt;属性值，该值第一次出现的位置，出现的次数&gt;,适用于有序的列或者可转为有序的列.下面给出一个具体的例子.下图给出一个身高的有序列，使用行程编码，可转化为两个三元组.为了便于管理，可以在三元组上构建索引.需要注意的是，该算法比较适合distinct值较少的列，因为如果列中不同的值较多，比如所有的值都不同，那么创建的三元组的数量就会很大，施展不出该算法的优势.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/run_length.png" alt=""></p><h3 id="位向量-Bit-Vector"><a href="#位向量-Bit-Vector" class="headerlink" title="位向量 Bit-Vector"></a>位向量 Bit-Vector</h3><p>位向量的核心思想是，将一个列中相同的值转为一个二元组&lt;属性值，在列中出现的位置的位图&gt;.下面给出一个简单的例子，图中给出的列是无序的，其中160这个值出现在第0、3、4、6个位置，162出现在第1、2、5个位置，则其位图的表示分别是1001101和0110010.使用该算法，整个列只要用两个简单的二元组就能表示出来.若列中distinct的值较少，则位图还可以用行程编码进行二次压缩.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/bit_vector.png" alt=""></p><h3 id="词典编码-Dictionary-Encoding"><a href="#词典编码-Dictionary-Encoding" class="headerlink" title="词典编码 Dictionary Encoding"></a>词典编码 Dictionary Encoding</h3><p>词典编码，顾名思义，主要针对的是字符串的压缩，核心思想是利用简短的编码代替列中某些重复出现的字符串，维护一个字符串与编码的映射，就可以快速确定编码所指代的字符串，这个映射也就是所谓的Dictionary.下面给出12年Google在VLDB论文<a href="http://dl.acm.org/citation.cfm?id=2350259&amp;CFID=761347277&amp;CFTOKEN=44019228" target="_blank" rel="noopener">Processing a trillion cells per mouse click</a>上有关这个算法的例子，将列search_string划分为三个块，每个块中都存在重复的字符串。首先创建一个全局的字典表global_dictionary，该表中包含了search_string中的所有distinct字符串，且每个字符串分配一个全局唯一的id.接着，为每个块也创建一个字典表chunk_dictionary，包含在该块中的所有distinct字符串，为每个字符串分配一个块范围内的id，并且将这个id与该字符串的全局id对应起来，通过这种二级字典表的方式，一个字符串就可以通过全局字典表映射到一个全局id，再通过块字典表映射到一个块id，这样快中就不用再存储真正的字符串了，而是字符串对应的块id，也就是图中的elements.例如要查找chunk 0中第4个element对应的字符串时，找到该element对应的块id是4，对应的全局id是12，再查找全局字典表可知，该element对应字符串”yellow pages”.同样该算法适用于列中distinct字符串较少的情况.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/dictionary_encoding.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在列数据库中，实用面向列的压缩算法进行数据压缩，并且在处理数据时保持压缩的形式，即不通过解压来处理数据，很大程度上提升了查询性能.凭直觉就能知道，以列为存储形式的数据比以行为存储形式的数据更容易压缩.当处理的数据信息熵较低，即数据的局部性较高，那么压缩算法的性能越好.举个列子来说吧，现在有一张顾客表，包含了[姓名，电话，邮箱，传真]等属性.列存储使得所有的姓名存储在一起，所有的电话号码存储在一起.有一点可以确定的是，电话号码各自之间是要比周围其他属性的数值来得更加相似的.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;压缩的优势具体是什么呢？&lt;/strong&gt;总结起来呢有两点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;减少I/O操作次数.如果数据被压缩了，那么其实一次I/O读取(磁盘到内存/CPU)实际对应的源数据是远远超过不使用压缩技术的读取.&lt;/li&gt;
&lt;li&gt;提高查询性能.如果查询执行器可以直接在压缩后的数据上进行操作，在进行具体的操作时不需要进行解压，而这个操作一般开销较大.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;列存储的压缩技术一般有消零和空格符算法(Null Supression)、Lerrpel-Ziv算法、词典编码算法(Dictionary Encoding)、行程编码算法(Run-length Encoding)、位向量算法(Bit-Vector Encoding)，其中较为常见的是后三种，接下来也重点介绍这三种.&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://tankcat2.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="压缩" scheme="http://tankcat2.com/tags/%E5%8E%8B%E7%BC%A9/"/>
    
      <category term="行程编码" scheme="http://tankcat2.com/tags/%E8%A1%8C%E7%A8%8B%E7%BC%96%E7%A0%81/"/>
    
      <category term="词典编码" scheme="http://tankcat2.com/tags/%E8%AF%8D%E5%85%B8%E7%BC%96%E7%A0%81/"/>
    
      <category term="位向量" scheme="http://tankcat2.com/tags/%E4%BD%8D%E5%90%91%E9%87%8F/"/>
    
  </entry>
  
  <entry>
    <title>“视图”漫游</title>
    <link href="http://tankcat2.com/2017/05/10/view/"/>
    <id>http://tankcat2.com/2017/05/10/view/</id>
    <published>2017-05-10T06:17:31.000Z</published>
    <updated>2017-07-20T00:47:04.000Z</updated>
    
    <content type="html"><![CDATA[<p>百度百科里面有关视图(View)的定义是，“指数据库中的视图，是一个虚拟表，其内容由查询定义”.</p><p>从用户的角度来看，一个视图是从一个<strong>特定的角度</strong>来查看数据库中的数据；</p><p>从数据库系统内部来看，视图是存储在数据库中的SQL Select语句，从一个或者多个基本表(相对于虚表而言)中导出的，和基本表类似，视图也包含行和列，但是在物理上不以存储的数据值集的形式存在.下面给出一张图来解释这段话的意思.从图上我们可以看出，数据库并没有对视图的数据进行物理上的存储，存储的只是视图的定义，也就是响应的Select.</p><a id="more"></a><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/view.jpg" alt=""></p><p>从数据库系统外部来看，视图就如同一张基本表，对基本表能够进行的一般操作都可以应用在视图上，比如增删改查.</p><p>那视图有优点呢？换句话说，<strong>为什么要使用视图呢？</strong>归纳起来有四点：</p><ol><li>简化负载查询.视图的定义是基于一个查询声明，这个查询声明可能关联了很多底层的表，可以使用视图向数据库的使用者或者外部程序隐藏复杂的底层表关系.</li><li>限制特定用户的数据访问权.处于安全原因，视图可以隐藏一些数据，比如社会保险基金表，可以用视图只显示姓名，地址，不显示社会保险号和工资数等.</li><li>支持列的动态计算.基本表一般都不支持这个功能，比如有一张<code>orders</code>订单表，包含产品数量<code>produce_num</code>与单价<code>produce_price_each</code>两个列，当需要查询总价时，就需要先查询出所有记录，再在代码中进行计算；而如果使用视图的话，只要在视图中添加一列<code>total_price(product_num*produce_price_each)</code>就可以直接查询出订单的总价了.</li><li>兼容旧版本.假设需要对数据库进行重新设计以适应一个新的业务需求，可能需要删除一些旧表，创建一些新表，但是又不希望这些变动会影响到那些旧程序，此时，就可以使用视图来适配那些旧程序.这就像公共API一样，无论内部发生什么改变，不影响上层的使用.</li></ol><p>既然说视图也是一种SQL语句，<strong>那么它和查询的区别是什么呢？</strong>简单来说，有三点：</p><ol><li>存储上，视图存储是数据库设计的一部分，而查询则不是；</li><li>更新限制上，因为视图来自于基本表，所以可间接地对基本表进行更新，但是存在诸多限制，比如不能在使用了group by语句的视图中插入值.</li><li>排序结果上，通过查询，可以对一个基本表进行排序，而视图不可以.</li></ol><p>此外，经常对视图的增删改查还是会转换为对基本表的增删改查，会不会降低操作的效率呢？其实未必，尤其是对于多表关联，视图创建后数据库内部会作出相应处理，建立对应的查询路径，反而有利于查询的效率，<strong>这就涉及到物化视图的知识了</strong>.</p><p><a href="https://en.wikipedia.org/wiki/Materialized_view" target="_blank" rel="noopener">维基百科里解释道，</a>物化视图(Materialized View)，也叫做快照，是包含了查询结果的数据库对象，可能是一个远程数据的本地副本，或者是一张表或连接结果的行或者列的子集，等.创建物化视图的过程有时候也被称作是物化，一种缓存查询结果的形式，类似于函数式编程中将函数值进行缓存，有时也称作是“预计算”，用来提高查询的性能与效率.</p><p>在关系型数据库中，如果涉及到对基本视图的查找或修改，都会转化为与之对应的基本表的查找或修改.而物化视图采取不同的方法.查询的结果被缓存在一个实体表中，而不是一个视图里，<strong>实际存储着数据的</strong>，这个实体表会随着基本表的更新而更新. 这种方法利用额外的存储代价和允许部分数据过期的代价，使得查询时的数据访问更加高效.在数据仓库中，物化视图经常使用，尤其是代价较大的频繁基本表查询操作.</p><p>和基本视图还有一点不同的是，在物化视图中，可以在任何一列上建立索引，相反，基本视图通常只能在与基本表相关的列上建立索引.</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;百度百科里面有关视图(View)的定义是，“指数据库中的视图，是一个虚拟表，其内容由查询定义”.&lt;/p&gt;
&lt;p&gt;从用户的角度来看，一个视图是从一个&lt;strong&gt;特定的角度&lt;/strong&gt;来查看数据库中的数据；&lt;/p&gt;
&lt;p&gt;从数据库系统内部来看，视图是存储在数据库中的SQL Select语句，从一个或者多个基本表(相对于虚表而言)中导出的，和基本表类似，视图也包含行和列，但是在物理上不以存储的数据值集的形式存在.下面给出一张图来解释这段话的意思.从图上我们可以看出，数据库并没有对视图的数据进行物理上的存储，存储的只是视图的定义，也就是响应的Select.&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://tankcat2.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="视图" scheme="http://tankcat2.com/tags/%E8%A7%86%E5%9B%BE/"/>
    
      <category term="物化视图" scheme="http://tankcat2.com/tags/%E7%89%A9%E5%8C%96%E8%A7%86%E5%9B%BE/"/>
    
  </entry>
  
  <entry>
    <title>近日爱读诗词</title>
    <link href="http://tankcat2.com/2017/05/09/poet/"/>
    <id>http://tankcat2.com/2017/05/09/poet/</id>
    <published>2017-05-09T04:44:31.000Z</published>
    <updated>2017-05-09T08:13:28.000Z</updated>
    
    <content type="html"><![CDATA[<center><br><strong>闲居初夏午睡起</strong><br><br>梅子留酸软齿牙，<br><br>芭蕉分绿与窗纱。<br><br>日长睡起无情思，<br><br>闲看儿童捉柳花。<br><br>ps:很喜欢杨万里的写景<br><br><a id="more"></a><br><br><strong>初夏即事</strong><br><br>石梁茅屋有弯碕，<br><br>流水溅溅度两陂。<br><br>晴日暖风生麦气，<br><br>绿阴幽草胜花时。<br><br>ps:读这首诗的那天正好是立夏<br><br><br><br><strong>苔</strong><br><br>白日不到处，<br><br>青春恰自来。<br><br>苔花如米小，<br><br>也学牡丹开。<br><br>ps:那日选这首诗是有原因的，自己阴差阳错地参加了学院的杰出青年评比。由于自己是保研来的华师大，现在又才研一，除了屈指可数的科研成果，其余方面均为有所建树。不出所料，只拿了一个靠亲朋好友投票来的人气奖。但是，个人成果的匮乏，没有使我退缩，依然自信上场，这毕竟也是一种锻炼，也可以看看别人是如何展示自己的。<br><br></center><p><br></p>]]></content>
    
    <summary type="html">
    
      &lt;center&gt;&lt;br&gt;&lt;strong&gt;闲居初夏午睡起&lt;/strong&gt;&lt;br&gt;&lt;br&gt;梅子留酸软齿牙，&lt;br&gt;&lt;br&gt;芭蕉分绿与窗纱。&lt;br&gt;&lt;br&gt;日长睡起无情思，&lt;br&gt;&lt;br&gt;闲看儿童捉柳花。&lt;br&gt;&lt;br&gt;ps:很喜欢杨万里的写景&lt;br&gt;&lt;br&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="诗词" scheme="http://tankcat2.com/tags/%E8%AF%97%E8%AF%8D/"/>
    
  </entry>
  
  <entry>
    <title>聚类索引与非聚类索引</title>
    <link href="http://tankcat2.com/2017/05/06/index/"/>
    <id>http://tankcat2.com/2017/05/06/index/</id>
    <published>2017-05-06T13:08:00.000Z</published>
    <updated>2017-07-20T00:47:26.000Z</updated>
    
    <content type="html"><![CDATA[<p>索引，是对数据库表中一列或者多列的值进行排序的一种数据结构，以便于快速访问数据库表的特定信息.如果没有索引，则需要遍历整张表，直到定位到所需的信息为止.可见，索引是用来<strong>定位</strong>的，加快数据库的查询速度.</p><h2 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h2><p>索引可分为聚集索引与非聚集索引.下面就两者分别介绍.</p><h3 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h3><p>在聚集索引中，表中行的物理顺序与索引的顺序相同，且一张表只能包含一个聚集索引.聚集索引类似物电话簿，索引可以包含一个或者多个列，类似电话簿按照姓氏和名字进行组织一样.</p><p>聚集索引很适用于那些经常要搜索范围值的列。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理上相邻.比如，若应用程序执行的某个查询经常检索某一个日期范围的记录，使用聚集索引可以迅速找到包含开始日期的行，接着检索相邻的行，直到到达结束日期.这样有助于提高类似查询的性能.</p><a id="more"></a><p>索引是通过<a href="http://blog.jobbole.com/24006/" target="_blank" rel="noopener">二叉树</a>的数据结构来描述的，我们可以这么理解聚集索引：索引的叶子节点就是数据节点，如下图所示.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/cluster.JPG" alt=""></p><h3 id="非聚集索引"><a href="#非聚集索引" class="headerlink" title="非聚集索引"></a>非聚集索引</h3><p>非聚集索引的逻辑顺序与表中行的物理存储数据不同，数据结构中的叶节点仍然是索引节点，有一个指针指向对应的数据块，如下图所示.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/noncluster.JPG" alt=""></p><h2 id="两者的区别"><a href="#两者的区别" class="headerlink" title="两者的区别"></a>两者的区别</h2><p>实际上，可把索引理解为一种特殊的目录。下面举个例子来说明一下聚集索引与非聚集索引的区别.</p><p>我们的汉语字典的正文本身就是一个聚集索引。比如，我们要查“安”字，就会很自然地翻开字典的前几页，因为“安”的拼音是“an”，而按照拼音排序汉字的字典是以英文字母“a”开头并以“z”结尾的，那么“安”字就自然地排在字典的前部。如果翻完了所有以“a”开头的部分仍然找不到这个字，那么就说明您的字典中没有这个字；同样的，如果查“张”字，那也会将您的字典翻到最后部分，因为“张”的拼音是“zhang”。也就是说，<strong>字典的正文部分本身就是一个目录</strong>，您不需要再去查其他目录来找到您需要找的内容。我们<strong>把这种正文内容本身就是一种按照一定规则排列的目录称为“聚集索引”</strong>。</p><p>如果我们认识某个字，可以快速地从自动中查到这个字。但也可能会遇到不认识的字，不知道它的发音，这时候，就不能按照刚才的方法找到我们要查的字，而需要去根据“偏旁部首”查到要找的字，然后根据这个字后的页码直接翻到某页来找到您要找的字。但结合“部首目录”和“检字表”而查到的字的排序并不是真正的正文的排序方法，比如查“张”字，我们可以看到在查部首之后的检字表中“张”的页码是672页，检字表中“张”的上面是“驰”字，但页码却是63页，“张”的下面是“弩”字，页面是390页。很显然，这些字并不是真正的分别位于“张”字的上下方，现在看到的连续的“驰、张、弩”三字实际上就是他们在<strong>非聚集索引中的排序</strong>，<strong>是字典正文中的字在非聚集索引中的映射</strong>。我们可以通过这种方式来找到您所需要的字，但它需要两个过程，先找到目录中的结果，然后再翻到所需要的页码。我们<strong>把这种目录纯粹是目录，正文纯粹是正文的排序方式称为“非聚集索引”</strong>。</p><p>通过以上例子，我们可以理解到什么是“聚集索引”和“非聚集索引”。进一步引申一下，我们可以很容易的理解：每个表只能有一个聚集索引，因为目录只能按照一种方法进行排序。</p><h2 id="两种索引的应用场合"><a href="#两种索引的应用场合" class="headerlink" title="两种索引的应用场合"></a>两种索引的应用场合</h2><table><thead><tr><th>动作描述</th><th>聚集索引</th><th>非聚集索引</th></tr></thead><tbody><tr><td>经常对列进行分组排序</td><td>√</td><td>√</td></tr><tr><td>返回某个范围内的数据</td><td>√</td><td>×</td></tr><tr><td>一个或者极少不同的值</td><td>×</td><td>×</td></tr><tr><td>小数目的不同值</td><td>√</td><td>×</td></tr><tr><td>大数目的不同值</td><td>×</td><td>√</td></tr><tr><td>频繁更新的列</td><td>×</td><td>√</td></tr><tr><td>频繁更新索引列</td><td>×</td><td>√</td></tr><tr><td>外键列</td><td>√</td><td>√</td></tr><tr><td>主键列</td><td>√</td><td>√</td></tr><tr><td></td><td></td><td></td></tr></tbody></table>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;索引，是对数据库表中一列或者多列的值进行排序的一种数据结构，以便于快速访问数据库表的特定信息.如果没有索引，则需要遍历整张表，直到定位到所需的信息为止.可见，索引是用来&lt;strong&gt;定位&lt;/strong&gt;的，加快数据库的查询速度.&lt;/p&gt;
&lt;h2 id=&quot;基本知识&quot;&gt;&lt;a href=&quot;#基本知识&quot; class=&quot;headerlink&quot; title=&quot;基本知识&quot;&gt;&lt;/a&gt;基本知识&lt;/h2&gt;&lt;p&gt;索引可分为聚集索引与非聚集索引.下面就两者分别介绍.&lt;/p&gt;
&lt;h3 id=&quot;聚集索引&quot;&gt;&lt;a href=&quot;#聚集索引&quot; class=&quot;headerlink&quot; title=&quot;聚集索引&quot;&gt;&lt;/a&gt;聚集索引&lt;/h3&gt;&lt;p&gt;在聚集索引中，表中行的物理顺序与索引的顺序相同，且一张表只能包含一个聚集索引.聚集索引类似物电话簿，索引可以包含一个或者多个列，类似电话簿按照姓氏和名字进行组织一样.&lt;/p&gt;
&lt;p&gt;聚集索引很适用于那些经常要搜索范围值的列。使用聚集索引找到包含第一个值的行后，便可以确保包含后续索引值的行在物理上相邻.比如，若应用程序执行的某个查询经常检索某一个日期范围的记录，使用聚集索引可以迅速找到包含开始日期的行，接着检索相邻的行，直到到达结束日期.这样有助于提高类似查询的性能.&lt;/p&gt;
    
    </summary>
    
      <category term="数据库" scheme="http://tankcat2.com/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
      <category term="索引" scheme="http://tankcat2.com/tags/%E7%B4%A2%E5%BC%95/"/>
    
  </entry>
  
  <entry>
    <title>&lt;刀锋&gt;观后感</title>
    <link href="http://tankcat2.com/2017/04/20/daofeng/"/>
    <id>http://tankcat2.com/2017/04/20/daofeng/</id>
    <published>2017-04-20T12:11:31.000Z</published>
    <updated>2017-05-05T12:09:24.000Z</updated>
    
    <content type="html"><![CDATA[<p>先摘抄一段刀锋里面我很喜欢的一段话，“For men and women are not only themselves; they are also the region in which they were born, the city apartment or the farm in which they learnt to walk, the games they played as children, the tales they overheard, the food they ate, the schools they attended, the sports they followed, the poets they read and the God they believed in. It is all these things that have made them what they are, and these are the things that you can’t come to know by hearsay, you can only know them if you have lived them. You can only know them if you are them.”</p><a id="more"></a><p>“因为人不论男男女女，都不仅仅是他们自身；他们也是自己出生的乡土，学步的农场或城市公寓，儿时玩的游戏，私下听来的山海经，吃的饭食，上的学校，关心的运动，吟哦的诗章，和信仰的上帝。这一切东西把他们造成现在这样，而这些东西都不是道听途说就可以了解的，你非得和那些人生活过。要了解这些，你就得是这些。 ”</p><p>无论中英文，都是一流的文字，解释了各种文化之间的冲突，以及冲突误解的永恒性。</p><p>很少有外国作品上让我读得这么舒服，这完全归功于周旭良老师的翻译功底，整本书翻译地非常好，读起来如沐春风。书写得很平淡，但每个角色都很有意思，拉里最为迷人。很奇怪，刚开始看的时候我脑子里对拉里的想象，居然是血战钢锯岭里的戴斯蒙特，这里也仅是人物形象。拉里一直追寻的答案，等同于追求终极真理，而这个问题最终都会归结到理性与精神的绝对满足。真的很难以想象，拉里这样的人，现实中又有多少，他们的生活又是怎样的？这种绝对的内心的泰然平和，我生生世世估计也做不到吧。</p>]]></content>
    
    <summary type="html">
    
      追随内心需求，探索人生价值与真谛.
    
    </summary>
    
      <category term="读书笔记" scheme="http://tankcat2.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="传记" scheme="http://tankcat2.com/tags/%E4%BC%A0%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>&lt;简明美国史&gt;观后感</title>
    <link href="http://tankcat2.com/2017/04/16/historyUSA/"/>
    <id>http://tankcat2.com/2017/04/16/historyUSA/</id>
    <published>2017-04-16T12:11:31.000Z</published>
    <updated>2017-05-05T12:08:22.000Z</updated>
    
    <content type="html"><![CDATA[<p>相对于厚重的、教科书式的历史文献，这是一本薄薄的，轻松的普及读本，没有平板数据，没有经济图表，却把把美国历史的端倪，黑暗，辉煌，血腥，光明清晰地勾勒出来。</p><a id="more"></a><p>有人说陈勤老师的这本美国史写得实在是太简太浅显，但是对我这种历史水平只停留在高中课本上的”史盲“来说，基本上是够了，从脉络上了解美国自1620年《五月花号公约》至2016年奥巴马最后的执政之间所发生的重大历史事件，这其中涵盖了美国从英属殖民地开始，到1776年《独立宣言》宣告独立，到1860年林肯领导南北战争，再到一战、二战、冷战，以及至今美国发生的种种。读完全书的第一感受是，陈勤老师应当是亲美派的，书中给我描述的美国是一个有趣、鲜活、有人味的美国，虽然对历史变革中发生的流血事件只是轻描淡写地带过，但还是能些许体会到”世界何尝不简单，历史从来不温柔“这一面。读完一遍脑海中对美国的历史线还是稍有混乱，有时间自己再整理整理。</p>]]></content>
    
    <summary type="html">
    
      青山遮不住，毕竟东流去.
    
    </summary>
    
      <category term="读书笔记" scheme="http://tankcat2.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
      <category term="历史" scheme="http://tankcat2.com/tags/%E5%8E%86%E5%8F%B2/"/>
    
  </entry>
  
  <entry>
    <title>再见我的暴力女王</title>
    <link href="http://tankcat2.com/2017/02/27/evil/"/>
    <id>http://tankcat2.com/2017/02/27/evil/</id>
    <published>2017-02-27T12:11:31.000Z</published>
    <updated>2017-11-26T06:16:11.104Z</updated>
    
    <content type="html"><![CDATA[<p>初二的时候，老妈同事的儿子来我家排练吹笛子，给我讲了生化危机3，当时没记住名字；</p><p>后来在家里的电脑上翻到了，还是没字幕英文版的，就这样看完了；</p><p>到了高二，周末回家，把第一部第二部给补完了，没看过瘾，导致后来第二部反复拿出来看，可能看了有十多遍了，里面的角色很鲜明，很喜欢吉尔，喜欢短发帅气的她；</p><p>没过多久，第四部就上映了，在网上看过一遍之后才去老文化馆那边的电影院再看一遍，记得那次的3D眼睛还是硬纸片做的；第五部也是在网上看的枪版，越来越没趣。</p><p>今天，和实验室的小伙伴一起看了终章，看完有点失落，追了这么多年的欧美暴力女王，就这么结束了。我不说这是情怀，有点装逼，但可能也是因为生化3，开始了我喜欢丧尸类型片子之路。等网上出了终章的未删减版，我要再刷一波。</p><p>最后，刚刚在知乎上看到“如何评价生化危机6”里面有个回答说，我觉得最大的彩蛋是我旁边的哥们儿看到女主骑着摩托绝尘而去的时候，突然说了一句，她真该进复联。。。</p><a id="more"></a>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;初二的时候，老妈同事的儿子来我家排练吹笛子，给我讲了生化危机3，当时没记住名字；&lt;/p&gt;
&lt;p&gt;后来在家里的电脑上翻到了，还是没字幕英文版的，就这样看完了；&lt;/p&gt;
&lt;p&gt;到了高二，周末回家，把第一部第二部给补完了，没看过瘾，导致后来第二部反复拿出来看，可能看了有十多遍了，里面的角色很鲜明，很喜欢吉尔，喜欢短发帅气的她；&lt;/p&gt;
&lt;p&gt;没过多久，第四部就上映了，在网上看过一遍之后才去老文化馆那边的电影院再看一遍，记得那次的3D眼睛还是硬纸片做的；第五部也是在网上看的枪版，越来越没趣。&lt;/p&gt;
&lt;p&gt;今天，和实验室的小伙伴一起看了终章，看完有点失落，追了这么多年的欧美暴力女王，就这么结束了。我不说这是情怀，有点装逼，但可能也是因为生化3，开始了我喜欢丧尸类型片子之路。等网上出了终章的未删减版，我要再刷一波。&lt;/p&gt;
&lt;p&gt;最后，刚刚在知乎上看到“如何评价生化危机6”里面有个回答说，我觉得最大的彩蛋是我旁边的哥们儿看到女主骑着摩托绝尘而去的时候，突然说了一句，她真该进复联。。。&lt;/p&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="生化危机" scheme="http://tankcat2.com/tags/%E7%94%9F%E5%8C%96%E5%8D%B1%E6%9C%BA/"/>
    
  </entry>
  
  <entry>
    <title>Kafka快速入门</title>
    <link href="http://tankcat2.com/2017/02/27/kafka_quickstart/"/>
    <id>http://tankcat2.com/2017/02/27/kafka_quickstart/</id>
    <published>2017-02-27T12:11:31.000Z</published>
    <updated>2017-07-20T00:48:16.000Z</updated>
    
    <content type="html"><![CDATA[<p>翻译自kafka documentation的quick start 部分。</p><ol><li><p>下载Zookeeper</p><p>我使用的是<a href="http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz" target="_blank" rel="noopener">zookeeper-3.4.6</a>版本</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf zookeeper-3.4.6.tgz</span><br><span class="line">cd zookeeper-3.4.6/conf</span><br></pre></td></tr></table></figure><p>将<code>zoo_example.cfg</code>改名为<code>zoo.cfg</code>，并在<code>/etc/profile</code>中设置环境变量：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line">export ZK_HOME=/home/admin/zookeeper-3.4.6</span><br><span class="line">export PATH=$PATH:$ZK_HOME/bin:$ZK_HOME/conf</span><br></pre></td></tr></table></figure></li></ol><a id="more"></a><ol><li><p>下载Kafka</p><p>我使用的是<a href="https://www.apache.org/dyn/closer.cgi?path=/kafka/0.10.2.1/kafka_2.10-0.10.2.1.tgz" target="_blank" rel="noopener">kafka_2.10-0.10.2.1</a>版本</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -xvzf kafka_2.10-0.10.2.1</span><br><span class="line">cd kafka_2.10-0.10.2.1/config</span><br></pre></td></tr></table></figure><p>接下来进行参数配置：<code>server.properties</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">vim server.properties</span><br><span class="line">...</span><br><span class="line"><span class="meta">#</span> 修改broker.id,全局唯一</span><br><span class="line"><span class="meta">#</span> 修改zookeeper.connect，形式为host:port，多个数据项用逗号分隔</span><br><span class="line">zookeeper.connect=192.168.115:2181</span><br><span class="line"><span class="meta">#</span> 设置话题的删除,默认值为false</span><br><span class="line">delete.topic.enable=true</span><br><span class="line"><span class="meta">#</span> 设置数据日志路径</span><br><span class="line">log.dirs=/home/admin/kafka_2.10-0.10.2.1/kafka-logs</span><br></pre></td></tr></table></figure></li><li><p>启动</p><p>Kafka使用Zookeeper，所以需要先启动Zookeeper，我没有使用Kafka内置的：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zkServer.sh start</span><br></pre></td></tr></table></figure><p>接着启动Kafka:</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure></li><li><p>创建topic</p><p>使用下面的命令创建名为<code>single_node</code>的topic，副本数为1，分区数为1，命令执行结束后，<code>kafka-logs</code>路径下就会生成一个<code>single_node-0</code>的文件夹。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.h --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic single_node</span><br></pre></td></tr></table></figure></li><li><p>发布与消耗数据</p><p>执行下面的命令创建producer进程，从标准输入中获取数据，并发送到Kafka集群中的single_node这个topic中，默认地，每一行将作为单独的一条信息发送出去。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic single_node</span><br><span class="line">wxt</span><br><span class="line">zf</span><br><span class="line">i love u</span><br></pre></td></tr></table></figure><p>执行下面的命令创建consumer进程，消耗指定topic的数据，这里就是标准输出的数据：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic single_node --from-beginning</span><br><span class="line">wxt</span><br><span class="line">zf</span><br><span class="line">i love u</span><br></pre></td></tr></table></figure></li></ol><p>以上均是单机版的Kafka配置与使用。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;翻译自kafka documentation的quick start 部分。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;下载Zookeeper&lt;/p&gt;
&lt;p&gt;我使用的是&lt;a href=&quot;http://mirrors.hust.edu.cn/apache/zookeeper/zookeeper-3.4.6/zookeeper-3.4.6.tar.gz&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;zookeeper-3.4.6&lt;/a&gt;版本&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;tar -xvzf zookeeper-3.4.6.tgz&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cd zookeeper-3.4.6/conf&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;将&lt;code&gt;zoo_example.cfg&lt;/code&gt;改名为&lt;code&gt;zoo.cfg&lt;/code&gt;，并在&lt;code&gt;/etc/profile&lt;/code&gt;中设置环境变量：&lt;/p&gt;
&lt;figure class=&quot;highlight shell&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;vim /etc/profile&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export ZK_HOME=/home/admin/zookeeper-3.4.6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;export PATH=$PATH:$ZK_HOME/bin:$ZK_HOME/conf&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;/li&gt;
&lt;/ol&gt;
    
    </summary>
    
      <category term="Kafka文档" scheme="http://tankcat2.com/categories/Kafka%E6%96%87%E6%A1%A3/"/>
    
    
      <category term="kafka" scheme="http://tankcat2.com/tags/kafka/"/>
    
  </entry>
  
  <entry>
    <title>Robust and Skew-resistant Parallel Joins in Shared-Nothing Systems</title>
    <link href="http://tankcat2.com/2017/01/17/Robust%20and%20Skew-resistant%20Parallel%20Joins%20in%20Shared-Nothing%20Systems/"/>
    <id>http://tankcat2.com/2017/01/17/Robust and Skew-resistant Parallel Joins in Shared-Nothing Systems/</id>
    <published>2017-01-17T05:11:31.000Z</published>
    <updated>2017-05-05T11:28:40.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="并行连接处理的两种基本框架"><a href="#并行连接处理的两种基本框架" class="headerlink" title="并行连接处理的两种基本框架"></a>并行连接处理的两种基本框架</h2><a id="more"></a><ul><li><p><strong>hash-based</strong> 基于哈希，如下图所示，分为四个步骤：</p><ol><li>partition划分，将原先每个节点上存储的$R_i$和$S_i$按照连接属性键的哈希值进行划分，比如图中，将第一个节点(大的实线矩形)中的$R_1$和$S_1$分别划分为k个子集；</li><li>distribution分发，根据连接属性键的哈希值，将上面的子集分发到另外一个空闲节点上，比如图中，将每个节点中的第k个子集$R<em>{ik}$ 和 $S</em>{ik}$ 同时分发到一个空闲节点上，那么这个空闲节点存储的数据为$R<em>k=\bigcup</em>{i=1}^{n}R_{ik}$,$S<em>k=\bigcup</em>{i=1}^{n}S_{ik}$;</li><li>build构建，在空闲节点中，对数据集$R_k$进行扫描，并对它构建一个存储在内存中的哈希表；</li><li>prob检测，在空闲节点中，对数据集$S_k$进行遍历，判断每一条数据的键值是否存在于上面构建的哈希表中，并输出连接结果.</li></ol><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/hash-based.png" alt="hash-based"></p></li><li><p><strong>duplication-based</strong> 基于副本，如下图所示，分为三个步骤：</p><ol><li>duplication复制，针对每个节点，将其中存储的数据集$R_i$广播到其他所有并行节点上(不是空余节点)，这样在广播操作结束后，所有节点上的数据集$R<em>k=\bigcup</em>{i=1}^{n}R_i=R$即为全集R；</li><li>build构建，构建哈希表，与hash-based相似；</li><li>prob检测，遍历另外一个数据集，输出连接结果，与hash-based相似.</li></ol></li></ul><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/duplicated-based.png" alt="duplicated-based"></p><h2 id="PRPD连接算法"><a href="#PRPD连接算法" class="headerlink" title="PRPD连接算法"></a>PRPD连接算法</h2><ol><li><p>PRPD定义：partial redistribution &amp; partition duplication，即将hash-based和duplication-based相结合.</p></li><li><p>处理流程，如下图所示：处理数据集R和S的连接，假设R是均匀分布，S是倾斜分布. 将每个节点中存储的S划分为两部分，$S<em>{loc}$是倾斜数据子集，$S</em>{redis}$是剩余的非倾斜数据子集.前者保留才原节点中不动，后者需要根据连接键值重新分发到一个空余节点中，类似与hash-based中的distribution操作. 同样，将每个节点中存储的R划分为两部分，$R<em>{dup}$是与$S</em>{loc}$连接键值相同的数据子集，$R<em>{redis}$是剩余的数据子集. 前者需要广播到其余所有的原节点中，类似于duplication-based中的duplication操作，后者需要根据连接键值重新分发到空余节点中，按照hash-based的最后两步，与$S</em>{redis}$进行连接.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/PRPD.jpg" alt="PRPD"></p></li><li><p>存在的问题：</p><ul><li>global skew，涉及到的对数据集S和R的划分需要预先获取每个节点上的倾斜键值的分布；</li><li>broadcasting，数据子集R的广播操作对网络负载施压，并且广播量将随着节点数量的增加而增加.</li></ul></li></ol><h2 id="本文提出算法"><a href="#本文提出算法" class="headerlink" title="本文提出算法"></a>本文提出算法</h2><p>PRPQ是基于两个可有效处理数据倾斜的分布式连接算法，semijoin-based和query-based. 基于这两者，提出改进.</p><h3 id="Semijoin-based-连接"><a href="#Semijoin-based-连接" class="headerlink" title="Semijoin-based 连接"></a>Semijoin-based 连接</h3><ol><li><p>semi-join的定义：半连接，从一个表中返回的行与另一个表中数据进行<strong>不完全</strong>连接查询，即查找到匹配的数据行就返回，不再继续查找.</p></li><li><p>semijoin-based连接，如下图所示. 数据集R和S在各自的属性a和b上做连接操作，分为以下四步骤：</p><ol><li>类似于hash-based中的第1,2两步，将各个节点中的数据集$R_i$按照连接属性的哈希值进行切分，再将元组分发到各自对应的空闲计算节点中(图中的红色虚线);</li><li>对各个节点中的数据集$S_i$在属性b上做投影操作得到$\pi_b(S_i)$，根据哈希值将这些属性b的unique key分发到计算节点中；</li><li>每个计算节点k收到数据集S的key 子集$\pi<em>b(S</em>{ik})$，和数据集R的子集$R<em>k=\bigcup</em>{i=1}^nR_{ik}$，对这两个子集做连接操作，将能连接上的R元组回发到各自的原节点i上(图中的③号线)；</li><li>各个原节点接收到retrieval返回的R集元组，与本地存储的S集元组做最后实际的连接操作，输出结果.</li></ol><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/semijoin.png" alt="semijoin"></p></li><li><p>特点：</p><ul><li>由于<strong>投影</strong>操作，S数据集只考虑unique key，而不考虑key的粒度，因此可以<strong>解决数据倾斜</strong>；</li><li>第2和第3步骤，只传输key和能连接上的元组，因此<strong>减轻了网络传输代价</strong>.</li><li>对于高选择性的连接，第2步和第3步中，S集的key和retrieval的R集元组交叠的数据量较大，仍然可能带来很大的网络通信量.</li></ul></li></ol><h3 id="Query-based-连接"><a href="#Query-based-连接" class="headerlink" title="Query-based 连接"></a>Query-based 连接</h3><ol><li><p>根据semijoin-based的第三个特点(存在的问题)，对第3和第4步进行改进，则有query-based连接算法.改进如下：</p><ol><li>若存在连接上的key和R集元组，则只返回value，而不是整个元组；若没有数据能连接上，则返回值为null的value；</li><li>返回的value和本地的S数据集做最后的实际连接操作，输出连接结果.</li></ol></li><li><p>特点：</p><ul><li>对于高选择性的连接处理，优势大，减轻网络通信负载；</li><li>对于低选择性的连接处理，存在问题，对于第3步没有能连接上的key，需要给返回的value赋值为null，以保证<key,value>的序列以便最后的连接处理，因此可能降低处理速度.</key,value></li></ul></li><li><p>折中综合：通过一个<strong>计数器</strong>来统计第3步骤中null出现的比例，从而动态地选择适合的方法，即当null比例较低时，使用query-based，否则使用semijoin-based.</p><h3 id="性能问题"><a href="#性能问题" class="headerlink" title="性能问题"></a>性能问题</h3><p>本文比较推崇直接在内存中进行连接计算，而不使用基于磁盘的计算框架比如MapReduce. 因此网络通信成本至关重要.当处理大规模的连接操作，上述两种方法都可能遭遇无法接受的网络通信负荷.</p><h3 id="PRPQ连接算法"><a href="#PRPQ连接算法" class="headerlink" title="PRPQ连接算法"></a>PRPQ连接算法</h3><ol><li><p>PRPQ定义：partial redistribution &amp; partial query，将hash-based和query-based相结合，如下图所示，分为四步骤：</p><ol><li><p>R distribution，与hash-based类似，将各个节点i上存储的数据集$R_i$根据连接属性a的哈希值，重新分发到一个空余计算节点上(图中红色虚线①)；</p></li><li><p>Push query keys，将各个节点i上存储的数据集$S_i$划分为两部分，低数据倾斜部分$S_i^{‘}$和高数据倾斜部分$h_i$. 根据连接属性b的哈希值，同时将$S_i^{‘}$的元组和$h_i$的投影unique key集合$\pi_b(h)$重新分发到对应的计算节点上(图中紫色虚线②)；</p></li><li>Return queried values，在每个计算节点k上，与hash-based的第3步类似，对集合$R<em>k=\bigcup</em>{i=1}^{n}R<em>{ik}$建立哈希表，(1). 对接收到的集合$\bigcup</em>{i=1}^{n}S_{ik}^{’}$进行遍历，并查找哈希表，直接输出连接结果；(2). 对接收到的key集合$\pi<em>b(h</em>{ik})$也遍历并查找路由表，如果没有匹配的key，则将retrieval的value置为null，若有匹配的key，则返回对应R的value.所有返回的value和节点k接收到key的顺序一致，并返回发送到原节点i；</li><li>Result lookup，接收到计算节点返回的value集合之后，在原节点中遍历value，并和本地存储的数据集S的高倾斜部分h进行连接，输出连接结果：若value为null，则继续扫描下一个；若不为空，则必定存在一个R和S的元组能连接上. 因此，最终的连接结果是第3步骤的部分结果$\bigcup$第4部分的连接结果.</li></ol><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/PRPQ.png" alt="PRPQ"></p></li><li><p>特点：</p><ul><li>与query-based算法相比<ol><li>当处理的数据集包含大量倾斜程度低的数据时，在网络上传送的query key以及对应的value的规模将相当小. 在倾斜程度为0的情况下，即为hash-based算法的实现.因此，PRPQ算法有效地弥补了query-based算法的缺点，提高了鲁棒性.</li><li>继承了query-based算法的优点，处理倾斜程度高的数据集时，大大减少网络通信量，因为高倾斜的元组并没有直接在网络上传输，而仅仅传输其unique key. </li></ol></li><li>与PRPD算法相比<ol><li>最主要的区别在于，使用query而不是duplication操作.</li><li>PRPQ涉及到的数据划分(第2步骤对S数据集进行倾斜程度的划分)，只定性分析局部的倾斜度，而不需要全局的；而PRPD需要获取全局数据集S的倾斜分布信息.关于如何定义全局倾斜，PRPD在连接操作之前将倾斜程度高的元组均匀分发到所有节点上.这个预处理操作会带来额外的通信代价.</li><li>对于倾斜程度中等mid-skew的元组，如何确定问题，PRPD使用广播的操作，可能导致节点负荷超载.</li></ol></li></ul></li></ol></li></ol><h2 id="算法实现"><a href="#算法实现" class="headerlink" title="算法实现"></a>算法实现</h2><p>每个节点上skew元组的提取是基于局部倾斜量化，因此引入一个阈值参数，即当一个key出现的次数超过该阈值，则视这个key为skewed. 下面先整理如何处理阈值参数，再整理PRPQ算法的具体实现.</p><h3 id="局部数据倾斜"><a href="#局部数据倾斜" class="headerlink" title="局部数据倾斜"></a>局部数据倾斜</h3><p>有很多方法可实现局部数据倾斜的快速监测，比如采样，扫描等.但是这些与本文的思路无关，所以本文仅仅在每个节点中对key的出现次数进行<strong>计数</strong>，按照降序排列，并保存到文件中. 在每一次的参数测试中，每个节点预先读取出现次数超过t的key，写入一个ArrayList中，并视它们为skew key.</p><h3 id="PRPQ具体实现"><a href="#PRPQ具体实现" class="headerlink" title="PRPQ具体实现"></a>PRPQ具体实现</h3><p>具体算法和前面的四个步骤一一对应，如下：</p><ol><li><p>在每个原节点中，将所有的元组读取到一个ArrayList中，处理数据集R的元组. 首先初始化一个R_c，用于收集分组的元组，R_c的初始化大小为计算节点的数量.接着，各个线程读取ArrayList中的R集元组，根据连接key的哈希值对元组进行分组.最后，将分好组的元组分发到对应的计算节点中(算法中的here表示当前计算节点的id).</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/RDistribution.png" alt="RDistribution"></p></li><li><p>根据给定的阈值参数t，对数据集S进行划分，倾斜的key被读入一个hashset，并且所有对应的元组被存储到一个hashmap中，剩余的非倾斜元组存储到一个$S^{’}_c$中.接着对hashmap进行投影操作，将所有的unique keys保存到key_c中.最后将key_c和$S^{’}_c$按照key的哈希值分发到对应的计算节点上.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/PushQueryKey.png" alt="PushQueryKey"></p></li><li><p>在计算节点中，对接收到的R集元组建立一个哈希表T’，对数据集$S’$元组进行遍历，并查找哈希表，若有匹配的key，则输出连接结果.同时遍历key集key_c，并查找哈希表，若不存在匹配的key，则返回值为null的value到对应的原节点，否则返回实际key对应的value.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/ReturnQueryValue.png" alt="ReturnQueryValue"></p></li><li><p>倾斜元组的连接结果可以通过遍历查询返回的value集合，若value为null，则不存在能连接上的S集元组，否则输出最终连接结果.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/ResultLookup.png" alt="ResultLookup"></p></li></ol><h2 id="实验对比"><a href="#实验对比" class="headerlink" title="实验对比"></a>实验对比</h2><p>数据集的选取：用作基准的数据集模仿决策支援系统下的连接操作.数据集R的cardinality为64M，数据集S的cardinality为1GB.由于数据仓储中数据一般以面向列的形式存储，所以实验中将数据格式设置为<key,value>的键值对，其中key和value均是8字节整型.</key,value></p><p>工作负载的选取：设置数据集R和S之间存在外键的关系，保持R的主键的unique，而在S中为对应的外键增加skew.除此之外，若S是统一分布的，它们中的每一个以相同的概率匹配关系R中的元组.对于倾斜的元组，它们的unique key在节点间均匀分布，并且每一个均能与R匹配上.下表给出了数据集S的分布情况.</p><table><thead><tr><th>S</th><th>key distribution</th><th>Partition</th><th>Size</th></tr></thead><tbody><tr><td>Zipf</td><td>skew=0,1,1.4</td><td>均匀evenly</td><td>512M</td></tr><tr><td>Linear</td><td>f(r)=46341-r,23170</td><td>排序范围sort-range</td><td>1GB,2GB</td></tr></tbody></table><p>Zipf分布中，skew=0表示统一分布，skew=1表示排名前十的key占据总量14%，skew=1.4表示排名前十的key占据总量68%.线性分布中，使用f(r)来描述key的分布情况，其中f(r)=46341-r表示频率最高的key出现46341次，频率第二的key出现46340次.使用该函数生成的数据集可以看作low-skewed的数据集.f(r)=23170表示所有的key都是均匀分布的，但是重复次数较高.f(r)对应的两个数据集均为1GB的大小，有46341个unique key.</p><p>R和S在计算节点中的分布情况：R均匀分布在所有的节点上，而S使用均匀和排序范围分布.均与分布保证每个计算节点上skewed元组的数量相同；排序范围分布是先将所有的元组按照键的频率排序，然后等分成大小一样的块，再将块按照次序分配到每个计算节点上.因此每个节点上skewed元组的数量差距可能会比较大.</p><p>实验共从运行时间、网络通信、负载均衡、可扩展性四个方面来进行比较.这里只就运行时间稍作整理.</p><h3 id="运行时间"><a href="#运行时间" class="headerlink" title="运行时间"></a>运行时间</h3><p>记录Hash-based算法、PRPD、PRPQ和query-based算法的运行时间，如下图所示.当S是均匀分布(第一组数据skew=0)，Hash、PRPD和PRPQ算法的性能相近，远远优于Query算法；当S是low skewed时，PRPD和PRPQ均比另外两种算法快；当S是high skewed时，Hash算法性能最差，而其余三种性能相近，则可得出结论，其余PRPD、PRPQ和Query可以较好地处理数据倾斜.随着skew程度的增加，Hash算法的执行时间增长剧烈，而Query算法呈现下降趋势.而PRPD和PRPQ算法呈现平稳的下降趋势.</p><p><img src="http://7xwggp.com1.z0.glb.clouddn.com/Runtime.png" alt="Runtime"></p><p>上图展示是选择最佳频率阈值t的性能，原文中关于不同阈值的实验这里不再整理，基本情况是无论t值如何变化以及分区计划如何，PRPQ的运行时间是低于PRPD的.</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;并行连接处理的两种基本框架&quot;&gt;&lt;a href=&quot;#并行连接处理的两种基本框架&quot; class=&quot;headerlink&quot; title=&quot;并行连接处理的两种基本框架&quot;&gt;&lt;/a&gt;并行连接处理的两种基本框架&lt;/h2&gt;
    
    </summary>
    
      <category term="论文阅读" scheme="http://tankcat2.com/categories/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"/>
    
    
      <category term="data skew" scheme="http://tankcat2.com/tags/data-skew/"/>
    
      <category term="parallel join" scheme="http://tankcat2.com/tags/parallel-join/"/>
    
  </entry>
  
  <entry>
    <title>使用Storm遇到的问题以及解决方案</title>
    <link href="http://tankcat2.com/2016/12/30/stormproblems/"/>
    <id>http://tankcat2.com/2016/12/30/stormproblems/</id>
    <published>2016-12-30T05:45:31.000Z</published>
    <updated>2017-01-17T12:32:46.000Z</updated>
    
    <content type="html"><![CDATA[<ol><li>集群中有3台服务器执行 storm supervisor命令后自动退出，supervisor起不来，后来在 logs目录下的supervisor.log日志文件中查到以下报错：</li></ol><a id="more"></a>   <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">2016</span>-<span class="number">12</span>-<span class="number">30</span> <span class="number">12</span>:<span class="number">41</span>:<span class="number">17.269</span> b.s.event [ERROR] Error when processing event</span><br><span class="line">java.lang.RuntimeException: java.lang.RuntimeException: java.io.FileNotFoundException: File <span class="string">'/home/admin/stormdata/data/supervisor/localstate/1480504905565'</span> does not exist</span><br><span class="line">at backtype.storm.utils.LocalState.partialSnapshot(LocalState.java:<span class="number">118</span>) ~[storm-core-<span class="number">0.10</span>.0.jar:<span class="number">0.10</span>.0]</span><br><span class="line">at backtype.storm.utils.LocalState.get(LocalState.java:<span class="number">126</span>) ~[storm-core-<span class="number">0.10</span>.0.jar:<span class="number">0.10</span>.0]</span><br><span class="line">at backtype.storm.local_state$ls_local_assignments.invoke(local_state.clj:<span class="number">83</span>) ~[storm-core-<span class="number">0.10</span>.0.jar:<span class="number">0.10</span>.0]</span><br><span class="line">at backtype.storm.daemon.supervisor$sync_processes.invoke(supervisor.clj:<span class="number">321</span>) ~[storm-core-<span class="number">0.10</span>.0.jar:<span class="number">0.10</span>.0]</span><br><span class="line">at clojure.lang.AFn.applyToHelper(AFn.java:<span class="number">154</span>) ~[clojure-<span class="number">1.6</span>.0.jar:?]</span><br><span class="line">at clojure.lang.AFn.applyTo(AFn.java:<span class="number">144</span>) ~[clojure-<span class="number">1.6</span>.0.jar:?]</span><br><span class="line">at clojure.core$apply.invoke(core.clj:<span class="number">626</span>) ~[clojure-<span class="number">1.6</span>.0.jar:?]</span><br><span class="line">at clojure.core$partial$fn__4228.doInvoke(core.clj:<span class="number">2468</span>) ~[clojure-<span class="number">1.6</span>.0.jar:?]</span><br><span class="line">at clojure.lang.RestFn.invoke(RestFn.java:<span class="number">397</span>) ~[clojure-<span class="number">1.6</span>.0.jar:?]</span><br><span class="line">at backtype.storm.event$event_manager$fn__7258.invoke(event.clj:<span class="number">40</span>) [storm-core-<span class="number">0.10</span>.0.jar:<span class="number">0.10</span>.0]</span><br><span class="line">at clojure.lang.AFn.run(AFn.java:<span class="number">22</span>) [clojure-<span class="number">1.6</span>.0.jar:?]</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">744</span>) [?:<span class="number">1.7</span>.0_45]</span><br></pre></td></tr></table></figure><p>   找不到’/home/admin/stormdata/data/supervisor/localstate/1480504905565’这个文件夹，网上找了下原因，给出的答案是<strong>stop the server without previously stop the supervisor</strong>，就是说可能是由于不正常关机造成状态不一致，具体原因不知，解决方案是<strong>删除stormdata/data/supervisor整个目录即可</strong>.</p><ol><li><p>在集群环境下日志清理，自己写了一个脚本clear-log.sh，主要是删除apache-storm-XXX下的logs文件里的日志文件，如下：</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">STORM_HOME=/home/admin/apache-storm-0.10.0　</span><br><span class="line">HOSTS_FILE=/home/admin/hosts.txt</span><br><span class="line">cat $HOSTS_FILE | while read line</span><br><span class="line">do</span><br><span class="line">ssh $line "rm -rf $STORM_HOME/logs/*" &lt; /dev/null</span><br><span class="line">done</span><br><span class="line">echo "remove log files...done"</span><br></pre></td></tr></table></figure></li></ol><p>其中STORM_HOME是storm的安装路径，hosts.txt是集群中各个节点的地址，我自己的配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">admin@10.11.1.53</span><br><span class="line">admin@10.11.1.40</span><br><span class="line">admin@10.11.1.41</span><br><span class="line">admin@10.11.1.42</span><br><span class="line">admin@10.11.1.45</span><br><span class="line">admin@10.11.1.46</span><br><span class="line">admin@10.11.1.51</span><br><span class="line">admin@10.11.1.53</span><br><span class="line">admin@10.11.1.54</span><br><span class="line">admin@10.11.1.55</span><br><span class="line">admin@10.11.1.56</span><br><span class="line">admin@10.11.1.58</span><br><span class="line">admin@10.11.1.60</span><br><span class="line">admin@10.11.1.64</span><br></pre></td></tr></table></figure><p>编辑完之后执行<code>chmod +x clear-log.sh</code>命令使得该文件获得可执行权限，再执行<code>./clear-log.sh</code>运行该脚本即可.</p>]]></content>
    
    <summary type="html">
    
      本文是我在使用Storm的过程中遇到的各种问题以及对应的解决方案，有些问题可能无法给出理由，不定期更新.
    
    </summary>
    
      <category term="Storm学习之路" scheme="http://tankcat2.com/categories/Storm%E5%AD%A6%E4%B9%A0%E4%B9%8B%E8%B7%AF/"/>
    
    
      <category term="Storm" scheme="http://tankcat2.com/tags/Storm/"/>
    
      <category term="日志" scheme="http://tankcat2.com/tags/%E6%97%A5%E5%BF%97/"/>
    
      <category term="环境配置" scheme="http://tankcat2.com/tags/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/"/>
    
  </entry>
  
  <entry>
    <title>关于苏打绿的题库</title>
    <link href="http://tankcat2.com/2016/10/26/knowledgebase/"/>
    <id>http://tankcat2.com/2016/10/26/knowledgebase/</id>
    <published>2016-10-26T08:26:31.000Z</published>
    <updated>2016-10-26T10:53:28.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-团队成员"><a href="#1-团队成员" class="headerlink" title="1.团队成员"></a>1.团队成员</h1><p> 6个人。<br> 吴青峰：主唱，1982.8.30，台湾台北，国立政治大学中文系，钢琴、口琴、口风琴、打击乐器、长笛<br> 谢馨仪：贝斯手，1982.4.16，台湾台北，国立政治大学科技管理研究所，贝斯、钢琴、摇滚吉他、古筝<br> 史俊威：鼓手，1979.8.26，台湾，国立政治大学社会系，吉他、鼓、口琴<br> <a id="more"></a><br> 龚钰祺：键盘手+中提琴手,1980.12.16，台湾，国立台北艺术大学音乐研究所，中提琴、钢琴、电子琴<br> 刘家凯：电子吉他手，1982.2.5，台湾台北，国立政治大学心理系、国立阳明大学脑科学研究所，吉他<br> 何景扬：木吉他手，1982.4.4，台湾，国立政治大学公共行政研究所，吉他、乌克丽丽</p><h1 id="2-重要时间节点"><a href="#2-重要时间节点" class="headerlink" title="2. 重要时间节点"></a>2. 重要时间节点</h1><p> 2001年成立于校园，2003年确立6人阵容，2004年5月，苏打绿正式出道，发行第一张单曲《空气中的视听与幻觉》。<br> 2005年，苏打绿发行了《SodaGreen》。<br> 2006年，苏打绿发行专辑《小宇宙》。<br> 2007年11月，苏打绿发行专辑《无与伦比的美丽》。<br> 2008年5月，苏打绿发行专辑《陪我歌唱》。<br> 韦瓦第计划：2009年5月8日，苏打绿发行了第五张专辑《春·日光》；2009年9月11日，苏打绿发行专辑《夏·狂热》；2013年9月18日，苏打绿发行专辑《秋：故事》，该专辑成为2013年度iTunes Store最受欢迎专辑；2015年9月23日，苏打绿发行专辑《冬·未了》。<br> 2011年<br> 2011年11月11日，苏打绿发行专辑《你在烦恼什么》。<br> 2014年，苏打绿开始了十周年世界巡回演唱会。</p><h1 id="3-唱片公司"><a href="#3-唱片公司" class="headerlink" title="3. 唱片公司"></a>3. 唱片公司</h1><p> 2004-2009，林浩哲音乐社；<br> 2009-至今，环球唱片</p><h1 id="4-“游乐园鱼丁糸”比赛题"><a href="#4-“游乐园鱼丁糸”比赛题" class="headerlink" title="4. “游乐园鱼丁糸”比赛题"></a>4. “游乐园鱼丁糸”比赛题</h1><h2 id="第一轮"><a href="#第一轮" class="headerlink" title="第一轮"></a>第一轮</h2><p> 单选题（以下各题四个选项中,只有一个选项正确）：</p><ol><li>EP《空气中的视听与幻觉》碟的颜色为：D<br>A、白B、红C、蓝D、墨绿</li><li>迄今为止仍未引进内地的苏打绿正式专辑是：A<br>A、无与伦比的美丽 B、小宇宙 C、同名专辑 D、陪我歌唱</li><li>青峰创作的第一首歌是：D<br>A、空气中的视听与幻觉 B、降落练习存在孪生基因 C、后悔莫及 D、窥</li><li>03年海洋音乐祭时，谁迟到了？C<br>A、家凯 B、阿福 C、小威D、青峰 </li><li>家凯、林暐哲法国街头赛跑谁赢了？A<br>A、家凯B、林暐哲C、都赢D、无法评判</li><li>图片题（见附件）：这张是苏打绿在大陆第一场演唱会（615北京场）的新闻图片，请问方框里面的人是谁？C<br>A、茶水 B、lfxfox C、博博鱼 D、和尚</li><li>苏打绿第一任的团长是谁？A<br>A.小威 B.阿福 C.馨仪 D.青峰 </li><li>苏打绿第一张同名专辑共有几首歌？D<br>A、2  B、3  C、10  D、11</li><li>苏打绿一共来过上海几次？B<br>A、1  B、2  C、3  D、4</li><li>苏打绿的第三张单曲是：C<br>A、空气中的视听与幻觉  B、飞鱼  C、Believe in music  D、迟到千年</li><li>苏打绿成军时间：B<br>A、2000  B、2001  C、2004  D、2005</li><li>“我想到你离开了以後，我们的城市好寂寞”选自苏打绿的哪首歌曲？B<br>A、无与伦比的美丽  B、雨中的操场  C、相信  D、城市</li><li>单曲《飞鱼》中有几首歌？D<br>A、1  B、2  C、3  D、4</li><li>苏打绿首次来内地时青峰裤子上的油漆是怎么来的：C<br>A、裤子本身印有的 B、被团员泼的 C、自己粉刷房间墙壁弄的D、不知道</li><li>以下苏打绿未上过的台湾综艺节目是：B<br>A、娱乐百分百 B、康熙来了 C、国光帮帮忙 D、大学生了没</li><li>第18届金曲奖最佳作曲人奖是因为哪首歌？B<br>A、小宇宙   B、小情歌   C、频率    D、飞鱼</li><li>红包场中，谁是王子造型的？D<br>A、青峰   B、家凯    C、阿龚    D、馨仪</li><li>小情歌是为了哪个艺人的唱片公司收歌而写？C<br>A、刘若英  B、江美琪  C、徐若瑄  D、杨乃文</li><li>《爱人动物》是以下哪部电影的主题曲？B<br>A、情非得已之生存之道  B、Juno  C、囧男孩  D、海角七号</li><li>「无与伦比的美丽」小巨蛋演唱会是几月几号？C<br>A、2007.11.1  B、2007.11.2  C、2007.11.3   D、2007.11.13</li></ol><h2 id="第二轮"><a href="#第二轮" class="headerlink" title="第二轮"></a>第二轮</h2><p> <img src="http://7xwggp.com1.z0.glb.clouddn.com/w0gab4.jpg" alt="高级题"><br> 单选题：<br> 1~5 BDB(D)CD<br> 6~10 CCCCB<br> 11~15DCCBC<br> 16~2 0ABADD<br> 多选题：<br> 1.BDEF<br> 2.CD<br> 3.BCDE<br> 4.AC<br> 5.ACD<br> 6.BCD<br> 7.ABC<br> 8.ABC<br> 9.ACD<br> 10.DE </p><h2 id="第三轮"><a href="#第三轮" class="headerlink" title="第三轮"></a>第三轮</h2><p> <img src="http://7xwggp.com1.z0.glb.clouddn.com/8zpkk9.jpg" alt="高级题"></p><h2 id="模拟题1"><a href="#模拟题1" class="headerlink" title="模拟题1"></a>模拟题1</h2><p>单选题：</p><ol><li>王菀之的首张国语创作专辑中多少首歌是由青峰作词？C<br>A、3  B、4   C、5  D、6</li><li>615北京演唱会开场歌曲是什么？A<br>A、无与伦比的美丽  B、小宇宙  C、小情歌  D、白日出没的月球</li><li>1224广州演唱会最后一首歌曲是：D<br>A、频率  B、小情歌  C、这天  D、陪我歌唱</li><li>苏打绿夺得了第几届海洋音乐祭的陪审团大奖？B<br>A、4  B、5  C、6  D、7</li><li>家凯是因为想参加什么音乐节而加入苏打绿的？B<br>A、春浪 B、春天呐喊 C、海洋音乐祭 D、简单生活</li><li>第一期空气中的视听与幻觉广播是06年几月几号？B<br>A、0906  B、1007  C、1017  D、1104</li><li>苏打绿的第一首抒情歌是：A<br>A、    频率  B、无言歌  C、背着你  D、小情歌</li><li>以下哪首是政大吉他社社歌？ C<br>A、天天想你 B、我的未来不是梦 C、我呼吸我感觉我存在 D、和天一样高</li><li>除了小巨蛋演唱会之外，哪一个影像保存了苏打绿《是我的海》的live演出？D<br>A、好友音乐会    B、周日狂热夜    C、摇滚风城音乐祭    D、 Taiwan Roc</li><li>在小巨蛋DVD中，青峰一共talking了多少次（不包括唱歌中以及预报下一首歌）？B<br>A、4次     B、5次     C、6次      D、7次</li><li>《Air》里的Bass是谁弹的？D<br>A、家凯     B、馨怡     C、阿福    D、阿龚</li><li>《搜包包》中谁全程站在家凯的面前？A<br>A、tirtir   B、小威   C、青峰   D、将将</li><li>《当代歌坛》第一次出现专写苏打绿的文章是哪一期？C<br>A、342期B、370期C、363期D、389期</li><li>创作给别人的歌中，青峰最喜欢哪首？A<br>A、女爵B、多希望你在C、穿墙人D、爱与奇异果</li><li>苏打绿中谁一直没有拿到高中毕业证书：D<br>A、家凯 B、阿龚 C、阿福 D、小威</li><li>在豆瓣公开现身过的苏打绿团员是：C<br>A、家凯 B、阿龚 C、阿福 D、小威</li><li>苏打绿现在的六人编制的第一次演出是在哪里？B<br>A、春天呐喊 B、政大金旋奖 C、西门町 D、海洋音乐祭</li></ol><p>多选题：</p><ol><li>下面不属于919上海演唱会安可曲目的是：DE<br>A、相信  B、这天  C、女爵  D、是我的海》  E、白日出没的月球</li><li>“搁浅”一词出现在以下哪些歌曲中：ABCE<br>A、吵  B、迟到千年  C、蓝眼睛 D、无与伦比的美丽  E、漂浮</li><li>青峰曾为以下哪些艺人写歌？ACDE<br>A、左光平  B、尚雯婕  C、张韶涵  D、刘若英  E、王菀之</li></ol><p>填空（每题5分，共5题）</p><ol><li>“各站停靠”演唱会上，作为舞台背景的钟显示的时间是<strong><strong>22:15__</strong></strong></li><li>2010年青峰和小威一起庆生时，其他团员送他们的礼物是<strong>_小时候照片拼贴出来的相框__</strong></li><li>阿福在自由发挥的歌曲<strong>_欢迎光临__</strong>的MV中客串演出了一个角色</li><li>各站停靠台中场的小礼物是<strong>_阿福面纸__</strong></li><li>苏打绿出道时候的第一支广告是<strong>_<em>蔡康永</em></strong>推荐的广播广告</li></ol><h2 id="模拟题2"><a href="#模拟题2" class="headerlink" title="模拟题2"></a>模拟题2</h2><p> 单选（以下各题，只有一个正确选项。每题5分，共10题）</p><ol><li>苏打绿二度踏上小巨蛋举办“日光狂热”演唱会前，媒体特地准备多样运动器材帮忙训练体力。结果，阿福在哪样器械上竟然输给了馨仪？C<br>A.滚轮  B.握力棒 C.哑铃 D.铁饼</li><li>青峰对自己人生过程进行总结的歌是 D<br>A.交响梦    B.融雪之前    C.相信    D.近未来</li><li>苏打绿、王菀之、方大同合作的903拉阔演唱会上，他们约定好各自代表的颜色，分别是 D<br>A.黑、白、绿        B.黑、绿、白<br>C.绿、黑、白        D.绿、白、黑</li><li>被媒体拍到跟青峰一起看电影，并且对镜头比中指的女友人是 A<br>A.小兔    B.张悬    C.娃娃    D.阿纯</li><li>歌词本的字型让“吴青峰写到手心手背都是肉”的专辑是 C<br>A. 苏打绿同名  B.春•日光  C.陪我歌唱   D.无与伦比的美丽</li><li>这是2010年5月苏打绿参加利物浦音乐节的返国记者会照片。请问青峰的这件衬衫，还在以下哪场公开表演中穿过？D<br>A.成都热波音乐节 B.北京原创A8颁奖礼 C.西安草莓音乐节 D.西湖音乐节</li><li>在《日光》MV中，和大家一起采茶的团员是：A<br>A.阿龚    B.小威    C.馨仪    D.家凯</li><li>来源于青峰日记的歌词是:C<br>A.近未来    B.女爵    C.困在    D.早点回家</li><li>苏打绿一共参与过几次简单生活节:C<br>A.1次    B.2次    C.3次    D.4次</li><li><p>阿福入伍前的饯别仪式上，第一个给阿福剪头发的团员是:A<br>A.青峰    B.馨仪    C.小威    D.家凯    </p><p>多选（以下各题有两个或两个以上的正确选项，多选、漏选、错选均不得分。每题5分，共5题）</p></li><li>在“最会睡”系列中，暐哲老师睡觉的地点有：ABCDE<br>A.馨仪家    B.伦敦录音室    C.草地     D.公司地板     E.会议室沙发</li><li>The Wall“多希望你在”系列演出的歌单中包含：ABCE<br>A.疼惜我的吻 B.吵 C.我在欧洲打电话给你 D.寂寞拥挤E.再见</li><li>“维瓦第计划”的歌词中，没有出现的意象是:BC<br>A.萤火虫    B.羔羊   C.海豚    D.白鸽    E.落叶</li><li>以下歌曲中，苏打绿有公开表演多个语言版本的是ACE<br>A.Oh Oh Oh Oh    B.飞鱼    C.无眠    D.日光    E.小情歌</li><li>游乐园的官方周边包括BCDE<br>A. .海报B.T恤 C.贴纸 D.徽章 E.年历</li></ol><p>填空题</p><ol><li>《小宇宙》这首歌标题的灵感来自<strong><strong>陈黎的《小宇宙》_</strong></strong>。</li><li>《小情歌》在被徐若瑄拒绝后，又被<strong><em>江美琪</em></strong>拒绝。</li><li><em>2005</em>年<strong>9_月</strong>3_日发行首张同名专辑《苏打绿》及进行全省签唱会表演。</li><li>青峰的小学时期，每天早上跟着跳的早操音乐是 我的未来不是梦。</li><li>无美丽电台的封面除了苏打绿六个人外还有谁？ 将将</li></ol><h1 id="5-获奖情况"><a href="#5-获奖情况" class="headerlink" title="5.获奖情况"></a>5.获奖情况</h1><ul><li>2016    第27届台湾金曲奖    最佳国语专辑奖     冬未了    （获奖）    </li><li>2016    第27届台湾金曲奖    最佳乐团奖    （获奖）    </li><li>2016    第27届台湾金曲奖    最佳编曲人奖    痛快的哀艳    （获奖）    </li><li>2015    第五届阿比鹿音乐奖    最受欢迎唱片    冬未了     （获奖）    </li><li>2014    第36届十大中文金曲    全年最高销量歌手    秋:故事    （获奖）    </li><li>2013    第7届无线咪咕汇音乐盛典    年度最受欢迎组合    韦瓦第计划    （获奖）    </li><li>2012    Hito流行音乐奖    hito乐团    （获奖）    </li><li>2011    第1届全球流行音乐金榜    年度最佳乐团    （获奖）    </li><li>2011    第1届全球流行音乐金榜    年度20大金曲    十年一刻    （获奖）    </li><li>2010    第10届华语音乐传媒大奖    最佳乐队    春·日光、夏/狂热    （获奖）    </li><li>2010    MusicRadio中国TOP排行榜    年度最受欢迎乐团    （获奖）    </li><li>2010    MusicRadio中国TOP排行榜    年度最佳乐团    （获奖）    </li><li>2010    新加坡金曲奖    最佳创作歌手    夏/狂热    （获奖）    </li><li>2010    新加坡金曲奖    最佳乐团    （获奖）    </li><li>2010    第21届金曲奖    最佳音乐录像带奖    日光    （获奖）    </li><li>2010    第21届金曲奖    最佳编曲人    日光    （提名）    </li><li>2010    第21届金曲奖    最佳乐团    春·日光    （提名）    </li><li>2010    第21届金曲奖    最佳乐团    夏/狂热    （提名）    </li><li>2009    第32届香港十大中文金曲颁奖典礼    全国最佳组合    （获奖）    </li><li>2009    MY Astro 至尊流行榜颁奖典礼    至尊组合/乐团    （获奖）    </li><li>2009    MY Astro 至尊流行榜颁奖典礼    至尊金曲20    狂热    （获奖）    </li><li>2009    第4届A8原创中国音乐盛典    年度最佳原创乐团    （获奖）    </li><li>2009    MUSIC RADIO中国TOP排行榜    港台年度最佳乐团    （获奖）    </li><li>2009    全球华语歌曲排行榜    地区杰出歌手奖    春·日光    （获奖）    </li><li>2009    全球华语歌曲排行榜    年度20大金曲    春·日光    （获奖）    </li><li>2009    全球华语歌曲排行榜    最佳编曲人    春·日光    （获奖）    </li><li>2009    全球华语歌曲排行榜    最佳乐团    春·日光    （获奖）    </li><li>2009    新城国语力颁奖礼    国语力亚洲乐团    （获奖）    </li><li>2009    新城国语力颁奖礼    国语力歌曲    日光    （获奖）    </li><li>2009    新城国语力颁奖礼    国语力乐团    （获奖）    </li><li>2009    新浪网络盛典    年度最佳乐团    （获奖）    </li><li>2008    第8届华语音乐传媒大奖    年度国语专辑    无与伦比的美丽    （获奖）    </li><li>2008    第8届华语音乐传媒大奖    最佳编曲人    白日出没的月球    （获奖）    </li><li>2008    第8届华语音乐传媒大奖    最佳乐队    无与伦比的美丽    （获奖）    </li><li>2008    香港新城国语颁奖礼    新城国语歌曲    陪我歌唱    （获奖）    </li><li>2008    香港新城国语颁奖礼    国语乐团    （获奖）    </li><li>2008    第9届CCTV/MTV音乐盛典    港台年度最佳组合    （获奖）    </li><li>2008    新城劲爆颁奖礼    新城全国乐迷投选劲爆突破表现大奖    （获奖）    </li><li>2008    新加坡金曲奖    最佳乐团    无与伦比的美丽    （获奖）    </li><li>2008    第19届金曲奖    最佳音乐录影带导演奖    左边    （提名）    </li><li>2008    第19届金曲奖    最佳年度歌曲    无与伦比的美丽    （提名）    </li><li>2008    第19届金曲奖    最佳编曲人    无与伦比的美丽    （提名）    </li><li>2008    第19届金曲奖    最佳乐团    无与伦比的美丽    （获奖）    </li><li>2007    新加坡金曲奖    最佳乐团    小宇宙    （获奖）    </li><li>2007    第44届金马奖    最佳原创电影歌曲    小情歌    （提名）    </li><li>2007    第18届金曲奖    最佳年度歌曲    小情歌    （提名）    </li><li>2007    第18届金曲奖    最佳国语专辑    小宇宙    （提名）    </li><li>2007    第18届金曲奖    最佳乐团    小宇宙    （获奖）    </li><li>2006    第17届金曲奖    最佳编曲人    Oh Oh Oh Oh    （提名）    </li><li>2004    MTV百万乐团挑战赛    网路最佳人气乐团    （获奖）    </li><li>2004    第5届海洋音乐祭    评审团大赏    （获奖）    </li><li>2002    政大第19届金旋奖    乐团组冠军    空气中的视听与幻觉    （获奖）    </li><li>2001    政大第18届金旋奖    乐团组最佳人气奖    （获奖）    <h1 id="6-老吴写给别人的歌"><a href="#6-老吴写给别人的歌" class="headerlink" title="6. 老吴写给别人的歌"></a>6. 老吴写给别人的歌</h1><h3 id="那英"><a href="#那英" class="headerlink" title="那英"></a>那英</h3>我的幸福刚刚好</li></ul><h3 id="林忆莲"><a href="#林忆莲" class="headerlink" title="林忆莲"></a>林忆莲</h3><p> 寂寞拥挤</p><h3 id="张惠妹"><a href="#张惠妹" class="headerlink" title="张惠妹"></a>张惠妹</h3><p> 掉了，你和我的时光</p><h3 id="李玟"><a href="#李玟" class="headerlink" title="李玟"></a>李玟</h3><p> 想你的夜</p><h3 id="莫文蔚"><a href="#莫文蔚" class="headerlink" title="莫文蔚"></a>莫文蔚</h3><p> 看着，老掉牙</p><h3 id="容祖儿"><a href="#容祖儿" class="headerlink" title="容祖儿"></a>容祖儿</h3><p> 在时间面前</p><h3 id="江蕙"><a href="#江蕙" class="headerlink" title="江蕙"></a>江蕙</h3><p> 你讲的话</p><h3 id="刘若英"><a href="#刘若英" class="headerlink" title="刘若英"></a>刘若英</h3><p> 没道理</p><h3 id="陶晶莹"><a href="#陶晶莹" class="headerlink" title="陶晶莹"></a>陶晶莹</h3><p> 翔</p><h3 id="蔡依林"><a href="#蔡依林" class="headerlink" title="蔡依林"></a>蔡依林</h3><p> 彩色相片，栅栏间隙偷窥你，迷幻</p><h3 id="杨丞琳"><a href="#杨丞琳" class="headerlink" title="杨丞琳"></a>杨丞琳</h3><p> 带我走，少年维特的烦恼，下个转弯是你吗，被自己绑架，一小节休息</p><h3 id="张韶涵"><a href="#张韶涵" class="headerlink" title="张韶涵"></a>张韶涵</h3><p> 最近好吗，刺情，蓝眼睛</p><h3 id="王心凌"><a href="#王心凌" class="headerlink" title="王心凌"></a>王心凌</h3><p> 从未到过的地方</p><h3 id="范玮琪"><a href="#范玮琪" class="headerlink" title="范玮琪"></a>范玮琪</h3><p> 坏了良心</p><h3 id="范晓萱"><a href="#范晓萱" class="headerlink" title="范晓萱"></a>范晓萱</h3><p> 开机关机</p><h3 id="杨乃文"><a href="#杨乃文" class="headerlink" title="杨乃文"></a>杨乃文</h3><p> 女爵</p><h3 id="许茹芸"><a href="#许茹芸" class="headerlink" title="许茹芸"></a>许茹芸</h3><p> 爱人动物，飞行时光，I will be with you，最难的是相遇，现在该怎么好，我留下的一个生活</p><h3 id="蔡健雅"><a href="#蔡健雅" class="headerlink" title="蔡健雅"></a>蔡健雅</h3><p> 极光，费洛蒙</p><h3 id="周笔畅"><a href="#周笔畅" class="headerlink" title="周笔畅"></a>周笔畅</h3><p> 别忘了</p><h3 id="谢安琪"><a href="#谢安琪" class="headerlink" title="谢安琪"></a>谢安琪</h3><p> 再见</p><h3 id="张悬"><a href="#张悬" class="headerlink" title="张悬"></a>张悬</h3><p> 两者</p><h3 id="徐佳莹"><a href="#徐佳莹" class="headerlink" title="徐佳莹"></a>徐佳莹</h3><p> 乐园</p><h3 id="魏如萱"><a href="#魏如萱" class="headerlink" title="魏如萱"></a>魏如萱</h3><p> 被雨伤透，困在，开机关机</p><h3 id="尚雯婕"><a href="#尚雯婕" class="headerlink" title="尚雯婕"></a>尚雯婕</h3><p> 什么？什么！</p><h3 id="吉克隽逸"><a href="#吉克隽逸" class="headerlink" title="吉克隽逸"></a>吉克隽逸</h3><p> 我唱故我在</p><h3 id="袁泉"><a href="#袁泉" class="headerlink" title="袁泉"></a>袁泉</h3><p> 等</p><h3 id="吴映洁"><a href="#吴映洁" class="headerlink" title="吴映洁"></a>吴映洁</h3><p> 一直</p><h3 id="刘容嘉"><a href="#刘容嘉" class="headerlink" title="刘容嘉"></a>刘容嘉</h3><p> 没有人爱</p><h3 id="潘玮仪"><a href="#潘玮仪" class="headerlink" title="潘玮仪"></a>潘玮仪</h3><p> 不同</p><h3 id="路嘉欣"><a href="#路嘉欣" class="headerlink" title="路嘉欣"></a>路嘉欣</h3><p> 穿墙人，当我继续唱</p><h3 id="王菀之"><a href="#王菀之" class="headerlink" title="王菀之"></a>王菀之</h3><p> 学会，迷湖，冬梦，是爱，爱与奇异果</p><h3 id="旅行团"><a href="#旅行团" class="headerlink" title="旅行团"></a>旅行团</h3><p> Bye Bye</p><h3 id="VOX玩声乐团"><a href="#VOX玩声乐团" class="headerlink" title="VOX玩声乐团"></a>VOX玩声乐团</h3><p> 让我做你的家，朱古力</p><h3 id="TFBOYS"><a href="#TFBOYS" class="headerlink" title="TFBOYS"></a>TFBOYS</h3><p> 小精灵</p><h3 id="谭咏麟"><a href="#谭咏麟" class="headerlink" title="谭咏麟"></a>谭咏麟</h3><p> 超越，糖衣陷阱，蓝侬梦，魔毯，算爱，未知</p><h3 id="张信哲"><a href="#张信哲" class="headerlink" title="张信哲"></a>张信哲</h3><p> 柔软</p><h3 id="陈奕迅"><a href="#陈奕迅" class="headerlink" title="陈奕迅"></a>陈奕迅</h3><p> 放弃治疗，这样的一个麻烦，谋情害命</p><h3 id="林俊杰"><a href="#林俊杰" class="headerlink" title="林俊杰"></a>林俊杰</h3><p> 独舞，爱的鼓励，裂缝中的阳光，不存在的情人</p><h3 id="萧敬腾"><a href="#萧敬腾" class="headerlink" title="萧敬腾"></a>萧敬腾</h3><p> 以爱之名，多希望你在</p><h3 id="杨宗纬"><a href="#杨宗纬" class="headerlink" title="杨宗纬"></a>杨宗纬</h3><p> 想对你说</p><h3 id="萧煌奇"><a href="#萧煌奇" class="headerlink" title="萧煌奇"></a>萧煌奇</h3><p> 下个街角</p><h3 id="信"><a href="#信" class="headerlink" title="信"></a>信</h3><p> 你存在，我记得，给自己的信</p><h3 id="左光平"><a href="#左光平" class="headerlink" title="左光平"></a>左光平</h3><p> 心里有鬼</p>]]></content>
    
    <summary type="html">
    
      AfterSummer抢票的关键呀~~第三轮答题木有找到答案！求神助攻！！！
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="苏打绿" scheme="http://tankcat2.com/tags/%E8%8B%8F%E6%89%93%E7%BB%BF/"/>
    
  </entry>
  
  <entry>
    <title>遇见小公举</title>
    <link href="http://tankcat2.com/2016/10/23/jielun/"/>
    <id>http://tankcat2.com/2016/10/23/jielun/</id>
    <published>2016-10-23T13:21:31.000Z</published>
    <updated>2016-10-23T13:29:02.000Z</updated>
    
    <content type="html"><![CDATA[<p>周杰伦是身边很多同龄人的偶像，他们应该从小学或者初中的时候就开始追他。同时期的还有蔡依林、张韶涵、林俊杰那些人，很奇怪当时我顶多是对他们的几首歌感兴趣，比如欧若拉，曹操，并没有萌生追星的概念。<br><a id="more"></a><br>我记不得听周杰伦的第一首歌是什么。小学六年级的时候我妈同事的女儿买了一个MP3,需要分外安电池的那种，里面有两首杰伦的歌，一首发如雪，一首夜曲。我借过来听，很喜欢这两首歌的旋律，后来搜到了歌词，就经常买花花绿绿的本子抄写歌词。到了初中，很多我很不喜欢的男生疯狂地迷恋周杰伦，可能因为女孩子成熟得早，特别反感他们自以为帅气的非主流风格（还有一个原因是很多喜欢周杰伦的人同时喜欢着许嵩）。本来因为杰伦不清楚的发音，我对他是无感的，但是因为一些烦人的粉丝，对歌手本人也没什么好感。后来到了大学，某个逗比室友对此和我惊人的相似。初中的时候我可能更多的是在追日漫，喜欢主题曲，还记得初二家里买电脑之前，星空卫视每天晚上6点放犬夜叉，我就拿着复读机录那首change the world。<br>到了高一，学校是明令禁止使用电子产品的，我用充饭卡的钱偷偷买了一个mp3,列了一个歌单让前桌的男生回家帮我下点歌，哪知道他全给我下的周杰伦。很幸运的是，他给我下的都是一些慢节奏情歌，最长的电影，给我一首歌的时间，甜甜的，说好的幸福呢，彩虹，七里香之类的。但也没有因为这些歌而粉上杰伦，还是听歌不看人的状态。<br>后来的后来，杰伦当了好声音的导师，看了一两期，发现他其实很个很可爱的人。再到现在，他的新专辑床边故事，那首前世情人，告白气球和now you see me，让我感觉，这就是从前那个酷酷的杰伦呀，那种我以前不屑的风格原来这么奇妙。于是一点没犹豫地在网易云上买了数字专辑。<br>今天大老远从上海跑到合肥听周杰伦的演唱会，虽然位子很不好，看不到人也算了，屏幕也看不到；虽然室外的音响效果也有点让人失望，那些快歌基本听不清歌词；虽然排队很长，座位坐得很乱…但是那些我自己很熟悉的旋律响起的时候，所有的举动只剩下舞动荧光棒，跟着一起唱。<br>让我印象很最深刻的是点歌环节，点到的第三个女孩子，杰伦问她是和谁一起来的，她说她一个人来的。当时杰伦愣了一下，然后安慰她说，全场的观众都是她的朋友，都陪着她听唱歌。当时我特别想去拥抱那个女生。一个人去看演唱会，身边都是情侣或者闺蜜团。你的注意力本该只放在爱豆身上，可无法避免的，有些场景，有些歌词就是会触动你内心那块最柔软的地方。这种经历我体验过。<br>错过了可以有多一点杰伦的年少时光有些遗憾，但也很幸运，我开始路转粉了，未来的路，还可以相伴而行。💗💗💗<br>ps:当然啦，如果能遇见一个喜欢人的一起去苏打绿的after summer，那么会更加幸运~~~</p>]]></content>
    
    <summary type="html">
    
      尽管是说遇见，其实连个大屏幕上的人脸都木有看到呀。。。
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="周杰伦" scheme="http://tankcat2.com/tags/%E5%91%A8%E6%9D%B0%E4%BC%A6/"/>
    
  </entry>
  
  <entry>
    <title>My Favorite Band</title>
    <link href="http://tankcat2.com/2016/10/17/sodagreen/"/>
    <id>http://tankcat2.com/2016/10/17/sodagreen/</id>
    <published>2016-10-17T12:02:31.000Z</published>
    <updated>2016-10-17T12:22:48.000Z</updated>
    
    <content type="html"><![CDATA[<p>Sodagreen is a Taiwanese indie band formed in 2001. Its member has been unchanged since 2003: lead vocals Wu Tsing-Fong, guitarist Liu Jia-Kai, guitarist Ho Jing-Yang, keyboardist Kung Yu-Chi, bass guitarist Hsieh Shin-Yi and drummer Shih Jun-Wei. The band was originally named by Shih and Wu affixed his favorite color, green, to the name.<br><a id="more"></a><br>Pure, artistic, indie, free, soft and simple. All of these are my impression of Sodagreen. The band is well known for its lead vocalist and songwriter Wu Tsing-Fong, who is excellent for his poetic lyrics, unique performing style and wide vocal range. As a typical Virgo, he is a paranoia that is disproportionate to an idol. He never does what an idol should do. He is unwilling to please the fans and doesn’t like to participate in the announcement program. To be a qualified artist is very hard; to be an artist who can satisfy all the fans is harder. I still remember the live show in Spring Wave Music And Art Festival this year. Sodagreen was arranged to the final appearance and didn’t finish all the songs in that the organizer advanced the end of the show and turned off the microphone domineeringly. Wu reluctantly left in the dark, but insisted on singing the rest of the songs through Weibo.</p><p>One of my favorite albums is “Summer/Fever”. Whenever I feel sad, I will listen to this album, which has inspiring power. It was released on September 11, 2009 and is their fifth full-length studio album. It is the second of the band’s Vivaldi Project, a planned series of four albums representing the four seasons respectively. The recording of this album took place in London and the songs were mostly written by the lead vocalist Wu. The album contains Britpop elements and lyrical references to the supernatural, Faust, Madame Butterfly, Don Quixote and the Greek god Dionysus. Among the songs of this album, I like “The Sound That Remains” best. In the lyrics, it draws an analogy between the sound of cicadas and the flood of public opinion, which narrows our horizon. I think the metaphor of the song is what Sodagreen has being teaching us: Don’t always mind about what other people think of you and just be free to pursue the self-value realization.</p><p>The Sodagreen’s last round of road show “After Summer” before their temporarily overturn has launched. I wish I could grab a ticket for the live show in Shanghai!</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Sodagreen is a Taiwanese indie band formed in 2001. Its member has been unchanged since 2003: lead vocals Wu Tsing-Fong, guitarist Liu Jia-Kai, guitarist Ho Jing-Yang, keyboardist Kung Yu-Chi, bass guitarist Hsieh Shin-Yi and drummer Shih Jun-Wei. The band was originally named by Shih and Wu affixed his favorite color, green, to the name.&lt;br&gt;
    
    </summary>
    
      <category term="随笔" scheme="http://tankcat2.com/categories/%E9%9A%8F%E7%AC%94/"/>
    
    
      <category term="苏打绿" scheme="http://tankcat2.com/tags/%E8%8B%8F%E6%89%93%E7%BB%BF/"/>
    
  </entry>
  
</feed>
